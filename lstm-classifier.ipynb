{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch\nimport string\nimport re\nfrom torchtext.data.utils import get_tokenizer\nfrom torch.nn.utils.rnn import pad_sequence\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.nn import functional as F\nfrom sklearn.preprocessing import LabelEncoder\nfrom torchtext.vocab import build_vocab_from_iterator\nimport torchtext.vocab as vocab","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-02-29T10:38:19.578746Z","iopub.execute_input":"2024-02-29T10:38:19.579033Z","iopub.status.idle":"2024-02-29T10:38:23.128530Z","shell.execute_reply.started":"2024-02-29T10:38:19.579007Z","shell.execute_reply":"2024-02-29T10:38:23.127479Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"training_df = pd.read_csv('/kaggle/input/twitter-entity-sentiment-analysis/twitter_training.csv', header=None)\ntraining_df.shape","metadata":{"execution":{"iopub.status.busy":"2024-02-29T10:38:23.129702Z","iopub.execute_input":"2024-02-29T10:38:23.130185Z","iopub.status.idle":"2024-02-29T10:38:23.367629Z","shell.execute_reply.started":"2024-02-29T10:38:23.130157Z","shell.execute_reply":"2024-02-29T10:38:23.366570Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"(74682, 4)"},"metadata":{}}]},{"cell_type":"code","source":"print(f'Shape before dropping nulls {training_df.shape}')\ntraining_df = training_df.dropna()\nprint(f'Shape after dropping nulls {training_df.shape}')","metadata":{"execution":{"iopub.status.busy":"2024-02-29T10:38:23.369065Z","iopub.execute_input":"2024-02-29T10:38:23.369608Z","iopub.status.idle":"2024-02-29T10:38:23.403495Z","shell.execute_reply.started":"2024-02-29T10:38:23.369574Z","shell.execute_reply":"2024-02-29T10:38:23.402362Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Shape before dropping nulls (74682, 4)\nShape after dropping nulls (73996, 4)\n","output_type":"stream"}]},{"cell_type":"code","source":"input_texts = training_df[3].tolist()\nprint(len(input_texts))\n\ntokenizer = get_tokenizer('basic_english')\n\ntokenized_texts = [tokenizer(text) for text in input_texts]\n# tokenized_texts = tokenized_texts\n\n\n\n# flattened_list = sum(tokenized_texts, [])\nflattened_list = [token for tokens in tokenized_texts for token in tokens]\n\nvocab = sorted(list(set(flattened_list)))\nword_to_id = {word:i+1 for i, word in enumerate(vocab)}\nid_to_word = {i+1:word for i, word in enumerate(vocab)}\n\nle = LabelEncoder()\ntraining_df['Labels']  = le.fit_transform(training_df[2])\noutput_y = training_df['Labels'].tolist()","metadata":{"execution":{"iopub.status.busy":"2024-02-29T10:38:23.407317Z","iopub.execute_input":"2024-02-29T10:38:23.407622Z","iopub.status.idle":"2024-02-29T10:38:25.309408Z","shell.execute_reply.started":"2024-02-29T10:38:23.407598Z","shell.execute_reply":"2024-02-29T10:38:25.308565Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"73996\n","output_type":"stream"}]},{"cell_type":"code","source":"encode_text = lambda x: [word_to_id[_] for _ in x]\n\nencoded_inputs = list(map(encode_text, tokenized_texts))\npadded = pad_sequence(list(map(torch.tensor, encoded_inputs)), batch_first=True)\noutput_y = torch.tensor(output_y, dtype=torch.float32).unsqueeze(-1)\noutput_y = output_y.type(torch.LongTensor)\npadded.shape, output_y.shape","metadata":{"execution":{"iopub.status.busy":"2024-02-29T10:38:25.310462Z","iopub.execute_input":"2024-02-29T10:38:25.310718Z","iopub.status.idle":"2024-02-29T10:38:27.285940Z","shell.execute_reply.started":"2024-02-29T10:38:25.310695Z","shell.execute_reply":"2024-02-29T10:38:27.285012Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"(torch.Size([73996, 311]), torch.Size([73996, 1]))"},"metadata":{}}]},{"cell_type":"code","source":"class Embedding(nn.Module):\n    def __init__(self, n_vocab, n_embed):\n        super().__init__()\n        self.embedding_layer = nn.Embedding(n_vocab, n_embed)\n        \n    def forward(self, x):\n        return self.embedding_layer(x)","metadata":{"execution":{"iopub.status.busy":"2024-02-29T10:38:27.287193Z","iopub.execute_input":"2024-02-29T10:38:27.287552Z","iopub.status.idle":"2024-02-29T10:38:27.293442Z","shell.execute_reply.started":"2024-02-29T10:38:27.287513Z","shell.execute_reply":"2024-02-29T10:38:27.292519Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"class LSTMClassifier(nn.Module):\n    def __init__(self, n_vocab, n_embed, n_hidden, timesteps, output):\n        super().__init__()\n        self.embedding = Embedding(n_vocab, n_embed)\n        self.lstm = nn.LSTM(n_embed, n_hidden, batch_first=True)\n        self.inter1 = nn.Linear(n_hidden, output)\n\n    def forward(self, x):\n        embeded = self.embedding(x)\n        out, (h, c) = self.lstm(embeded)\n        out = self.inter1(out[:, -1])\n        return out\n    ","metadata":{"execution":{"iopub.status.busy":"2024-02-29T10:38:27.294400Z","iopub.execute_input":"2024-02-29T10:38:27.294639Z","iopub.status.idle":"2024-02-29T10:38:27.307157Z","shell.execute_reply.started":"2024-02-29T10:38:27.294617Z","shell.execute_reply":"2024-02-29T10:38:27.306418Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"execution":{"iopub.status.busy":"2024-02-29T10:38:27.308129Z","iopub.execute_input":"2024-02-29T10:38:27.308419Z","iopub.status.idle":"2024-02-29T10:38:27.367601Z","shell.execute_reply.started":"2024-02-29T10:38:27.308396Z","shell.execute_reply":"2024-02-29T10:38:27.366748Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"cell_type":"code","source":"split = 0.8\ntrain_size = int(split * padded.shape[0])\n\nx_train, x_val, y_train, y_val = padded[:train_size], padded[train_size:], output_y[:train_size], output_y[train_size:]\nx_train, x_val, y_train, y_val = x_train.to(device), x_val.to(device), y_train.to(device), y_val.to(device)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-02-29T10:38:27.368781Z","iopub.execute_input":"2024-02-29T10:38:27.369134Z","iopub.status.idle":"2024-02-29T10:38:27.533247Z","shell.execute_reply.started":"2024-02-29T10:38:27.369100Z","shell.execute_reply":"2024-02-29T10:38:27.532425Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def train_epoch(x_batch, y_batch):\n    optimizer.zero_grad()\n    output = model(x_batch)\n    \n    loss = loss_function(output, y_batch.view(-1))\n\n    loss.backward()\n    optimizer.step()\n    \n    return loss","metadata":{"execution":{"iopub.status.busy":"2024-02-29T10:38:27.534260Z","iopub.execute_input":"2024-02-29T10:38:27.534526Z","iopub.status.idle":"2024-02-29T10:38:27.539980Z","shell.execute_reply.started":"2024-02-29T10:38:27.534503Z","shell.execute_reply":"2024-02-29T10:38:27.538924Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"n_embed = 128\ntimesteps = padded.shape[-1]\nn_hidden = 64\n# model = Encoder(len(vocab) + 1, n_embed, timesteps, head_size=16, output=4)\nmodel = LSTMClassifier(len(vocab) + 1, n_embed, n_hidden, timesteps, 4)\nbatch_size = 32\nbatch_per_epoch = x_train.shape[0] // batch_size\n\n# loss_function = nn.BCELoss()\nloss_function = nn.CrossEntropyLoss()\nlearning_rate = 0.001 \noptimizer = optim.Adam(model.parameters(), lr=learning_rate)\n\n# Set the device (CPU or GPU)\nmodel.to(device)\n# model = torch.nn.DataParallel(model, device_ids = [0,1]).to(device)\n# output_y = output_y.type(torch.LongTensor)\n# inputs, targets, masked_reshape = padded.to(device), output_y.to(device), masked_reshape.to(device)\n\nfor epoch in range(10):\n    train_loss = 0\n    for i in range(batch_per_epoch):\n        start = i * batch_size\n        x_batch, y_batch = x_train[start:start+batch_size], y_train[start:start+batch_size]\n\n        model.train(True)\n        loss = train_epoch(x_batch, y_batch)\n        train_loss += loss\n        \n    print(f'Epoch {epoch} Loss: {train_loss / (i+1)}')   \n    model.eval()\n    with torch.no_grad():\n        output_val = model(x_val)\n        loss_val = loss_function(output_val, y_val.view(-1))\n        print(f'Epoch {epoch} Val loss: {loss_val}')\n        \n    print()","metadata":{"execution":{"iopub.status.busy":"2024-02-29T10:40:11.839562Z","iopub.execute_input":"2024-02-29T10:40:11.840434Z","iopub.status.idle":"2024-02-29T10:40:18.969435Z","shell.execute_reply.started":"2024-02-29T10:40:11.840402Z","shell.execute_reply":"2024-02-29T10:40:18.968029Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Epoch 0 Loss: 1.3612509965896606\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","Cell \u001b[0;32mIn[12], line 33\u001b[0m\n\u001b[1;32m     31\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 33\u001b[0m     output_val \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_val\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m     loss_val \u001b[38;5;241m=\u001b[39m loss_function(output_val, y_val\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Val loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss_val\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","Cell \u001b[0;32mIn[7], line 10\u001b[0m, in \u001b[0;36mLSTMClassifier.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m      9\u001b[0m     embeded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding(x)\n\u001b[0;32m---> 10\u001b[0m     out, (h, c) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43membeded\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minter1(out[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/rnn.py:879\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    876\u001b[0m         hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[1;32m    878\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 879\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m                      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    882\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\u001b[38;5;28minput\u001b[39m, batch_sizes, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[1;32m    883\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional)\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 21.97 GiB. GPU 0 has a total capacty of 14.75 GiB of which 6.55 GiB is free. Process 5761 has 8.19 GiB memory in use. Of the allocated memory 8.02 GiB is allocated by PyTorch, and 26.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"],"ename":"OutOfMemoryError","evalue":"CUDA out of memory. Tried to allocate 21.97 GiB. GPU 0 has a total capacty of 14.75 GiB of which 6.55 GiB is free. Process 5761 has 8.19 GiB memory in use. Of the allocated memory 8.02 GiB is allocated by PyTorch, and 26.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","output_type":"error"}]}]}