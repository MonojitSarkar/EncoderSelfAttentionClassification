{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3176,"sourceType":"datasetVersion","datasetId":1835},{"sourceId":2510329,"sourceType":"datasetVersion","datasetId":1520310}],"dockerImageVersionId":30648,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch\nimport string\nimport re\nfrom torchtext.data.utils import get_tokenizer\nfrom torch.nn.utils.rnn import pad_sequence\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.nn import functional as F\nfrom sklearn.preprocessing import LabelEncoder\nfrom torchtext.vocab import build_vocab_from_iterator\nimport torchtext.vocab as vocab","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-02-29T08:07:01.480673Z","iopub.execute_input":"2024-02-29T08:07:01.481525Z","iopub.status.idle":"2024-02-29T08:07:10.054944Z","shell.execute_reply.started":"2024-02-29T08:07:01.481471Z","shell.execute_reply":"2024-02-29T08:07:10.053636Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"training_df = pd.read_csv('/kaggle/input/twitter-entity-sentiment-analysis/twitter_training.csv', header=None)\ntraining_df.shape","metadata":{"execution":{"iopub.status.busy":"2024-02-29T08:07:10.057262Z","iopub.execute_input":"2024-02-29T08:07:10.057871Z","iopub.status.idle":"2024-02-29T08:07:10.430022Z","shell.execute_reply.started":"2024-02-29T08:07:10.057834Z","shell.execute_reply":"2024-02-29T08:07:10.428644Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"(74682, 4)"},"metadata":{}}]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"training_df.sample(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'Shape before dropping nulls {training_df.shape}')\ntraining_df = training_df.dropna()\nprint(f'Shape after dropping nulls {training_df.shape}')","metadata":{"execution":{"iopub.status.busy":"2024-02-29T08:07:10.432202Z","iopub.execute_input":"2024-02-29T08:07:10.432664Z","iopub.status.idle":"2024-02-29T08:07:10.472365Z","shell.execute_reply.started":"2024-02-29T08:07:10.432629Z","shell.execute_reply":"2024-02-29T08:07:10.471174Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Shape before dropping nulls (74682, 4)\nShape after dropping nulls (73996, 4)\n","output_type":"stream"}]},{"cell_type":"code","source":"training_df.loc[:, 3] = training_df.loc[:, 3].str.replace(re.escape(string.punctuation), ' ', regex=True)\ntraining_df.loc[:, 3] = training_df.loc[:, 3].str.replace(',', ' ', regex=True)","metadata":{"execution":{"iopub.status.busy":"2024-02-29T08:07:10.474718Z","iopub.execute_input":"2024-02-29T08:07:10.475525Z","iopub.status.idle":"2024-02-29T08:07:10.628179Z","shell.execute_reply.started":"2024-02-29T08:07:10.475462Z","shell.execute_reply":"2024-02-29T08:07:10.626360Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"input_texts = training_df[3].tolist()\nprint(len(input_texts))\n\ntokenizer = get_tokenizer('basic_english')\n\ntokenized_texts = [tokenizer(text) for text in input_texts]\n# tokenized_texts = tokenized_texts\n\n\n\n# flattened_list = sum(tokenized_texts, [])\nflattened_list = [token for tokens in tokenized_texts for token in tokens]\n\nvocab = sorted(list(set(flattened_list)))\nword_to_id = {word:i+1 for i, word in enumerate(vocab)}\nid_to_word = {i+1:word for i, word in enumerate(vocab)}\n\nle = LabelEncoder()\ntraining_df['Labels']  = le.fit_transform(training_df[2])\noutput_y = training_df['Labels'].tolist()","metadata":{"execution":{"iopub.status.busy":"2024-02-29T08:07:10.629832Z","iopub.execute_input":"2024-02-29T08:07:10.631373Z","iopub.status.idle":"2024-02-29T08:07:12.641642Z","shell.execute_reply.started":"2024-02-29T08:07:10.631316Z","shell.execute_reply":"2024-02-29T08:07:12.640405Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"73996\n","output_type":"stream"}]},{"cell_type":"code","source":"# Read glove embeddings\nglove_path = '/kaggle/input/glove-global-vectors-for-word-representation/glove.6B.100d.txt'\n\nwith open(glove_path, 'r') as file:\n     lines = file.readlines()\n\nprint(len(lines))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"word_to_vec = dict()\nfor line in lines:\n    word_and_vec = line.split(' ', maxsplit=1)\n    word, vec = word_and_vec[0], word_and_vec[1]\n    vec_array = np.fromstring(vec, sep=' ').astype('float32')\n    word_to_vec[word] = vec_array\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_x = ['I loved the movie', 'The product exceeded my expectations', 'The service was terrible', 'The performance of the device is disappointing']\noutput_y = [1, 1, 0, 0]\n\ninput_x = list(map(str.lower, input_x))\ntokenized_inputs = [tokenizer(text) for text in input_x]\nflattened_list = sum(tokenized_inputs, [])\nprint(flattened_list)\nvocab = sorted(list(set(flattened_list)))\nword_to_id = {word:i+1 for i, word in enumerate(vocab)}\nid_to_word = {i+1:word for i, word in enumerate(vocab)}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encode_text = lambda x: [word_to_id[_] for _ in x]\n\nencoded_inputs = list(map(encode_text, tokenized_texts))\npadded = pad_sequence(list(map(torch.tensor, encoded_inputs)), batch_first=True)\noutput_y = torch.tensor(output_y, dtype=torch.float32).unsqueeze(-1)\npadded.shape, output_y.shape","metadata":{"execution":{"iopub.status.busy":"2024-02-29T08:07:12.643367Z","iopub.execute_input":"2024-02-29T08:07:12.644098Z","iopub.status.idle":"2024-02-29T08:07:14.998872Z","shell.execute_reply.started":"2024-02-29T08:07:12.644055Z","shell.execute_reply":"2024-02-29T08:07:14.997087Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"(torch.Size([73996, 311]), torch.Size([73996, 1]))"},"metadata":{}}]},{"cell_type":"code","source":"B, T = padded.shape\nmask = torch.eq(padded, 0).to(torch.float32)\nmask = mask * -1e9\nmasked_reshape = mask.reshape(B, 1, T)","metadata":{"execution":{"iopub.status.busy":"2024-02-29T08:07:15.001477Z","iopub.execute_input":"2024-02-29T08:07:15.002093Z","iopub.status.idle":"2024-02-29T08:07:15.231364Z","shell.execute_reply.started":"2024-02-29T08:07:15.002055Z","shell.execute_reply":"2024-02-29T08:07:15.230118Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"class Embedding(nn.Module):\n    def __init__(self, n_vocab, n_embed):\n        super().__init__()\n        self.embedding_layer = nn.Embedding(n_vocab, n_embed)\n        \n    def forward(self, x):\n        return self.embedding_layer(x)","metadata":{"execution":{"iopub.status.busy":"2024-02-29T08:07:22.811791Z","iopub.execute_input":"2024-02-29T08:07:22.812201Z","iopub.status.idle":"2024-02-29T08:07:22.817705Z","shell.execute_reply.started":"2024-02-29T08:07:22.812174Z","shell.execute_reply":"2024-02-29T08:07:22.816561Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"class Head(nn.Module):\n    def __init__(self, head_size=16):\n        super().__init__()\n        self.query = nn.Linear(n_embed, head_size)\n        self.key = nn.Linear(n_embed, head_size)\n        self.value = nn.Linear(n_embed, head_size)\n        \n    def forward(self, x, mask):\n        B, T, C = x.shape\n        \n        query = self.query(x)\n        key = self.key(x)\n        value = self.value(x)\n        \n        wei = query @ key.transpose(-2, -1)\n        \n        if mask is not None:\n            wei = wei + mask\n        \n        wei = F.softmax(wei, dim=-1)\n        out = wei @ value # (B, T, head_size)\n        \n        return out","metadata":{"execution":{"iopub.status.busy":"2024-02-29T08:07:27.822714Z","iopub.execute_input":"2024-02-29T08:07:27.823099Z","iopub.status.idle":"2024-02-29T08:07:27.831671Z","shell.execute_reply.started":"2024-02-29T08:07:27.823043Z","shell.execute_reply":"2024-02-29T08:07:27.830167Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"execution":{"iopub.status.busy":"2024-02-29T08:07:34.863308Z","iopub.execute_input":"2024-02-29T08:07:34.863696Z","iopub.status.idle":"2024-02-29T08:07:34.871548Z","shell.execute_reply.started":"2024-02-29T08:07:34.863668Z","shell.execute_reply":"2024-02-29T08:07:34.870315Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"device(type='cpu')"},"metadata":{}}]},{"cell_type":"code","source":"class Encoder(nn.Module):\n    def __init__(self, n_vocab, n_embed, timesteps, head_size, output):\n        super().__init__() # What happens if I pass the class name in super?\n        self.embedding = Embedding(n_vocab, n_embed)\n        self.positional_encodings = self.get_positional_embeddings(self.get_angle(timesteps, n_embed)).to(device)\n        self.sa = Head(head_size)\n        self.inter1_layer = nn.Linear(head_size, timesteps)\n        self.output = nn.Linear(timesteps**2, output)\n        \n    def forward(self, x, mask):\n        B, T = x.shape\n        embedding = self.embedding(x) + self.positional_encodings # (B, timesteps, n_embed)\n        sa_out = self.sa(embedding, mask) # (B, timesteps, head_size)\n        inter1 = self.inter1_layer(sa_out) # (B, timesteps, head_size) @ (head_size, timesteps) --> (B, timesteps, timesteps)\n        output = self.output(inter1.view(B, -1))\n#         output = F.softmax(output, dim=-1)\n        \n        return output\n    \n    def get_angle(self, timesteps, dim):\n        k = np.arange(dim)[np.newaxis, :]\n        i = k // 2\n        \n        positions = np.arange(timesteps)[:, np.newaxis]\n        angles = positions / (10000 ** (2*i/dim))\n        \n        return angles\n    \n    def get_positional_embeddings(self, angles):\n        angles[:, 0::2] = np.sin(angles[:, 0::2])\n        angles[:, 1::2] = np.cos(angles[:, 1::2])\n        \n        return torch.tensor(angles, dtype=torch.float32)","metadata":{"execution":{"iopub.status.busy":"2024-02-29T08:07:48.514141Z","iopub.execute_input":"2024-02-29T08:07:48.514555Z","iopub.status.idle":"2024-02-29T08:07:48.525299Z","shell.execute_reply.started":"2024-02-29T08:07:48.514522Z","shell.execute_reply":"2024-02-29T08:07:48.524071Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"training_df[2].unique()","metadata":{"execution":{"iopub.status.busy":"2024-02-29T08:11:44.302939Z","iopub.execute_input":"2024-02-29T08:11:44.303316Z","iopub.status.idle":"2024-02-29T08:11:44.317780Z","shell.execute_reply.started":"2024-02-29T08:11:44.303288Z","shell.execute_reply":"2024-02-29T08:11:44.316270Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"array(['Positive', 'Neutral', 'Negative', 'Irrelevant'], dtype=object)"},"metadata":{}}]},{"cell_type":"code","source":"y_batch.view(-1).shape","metadata":{"execution":{"iopub.status.busy":"2024-02-29T08:07:56.082633Z","iopub.execute_input":"2024-02-29T08:07:56.083003Z","iopub.status.idle":"2024-02-29T08:07:56.199150Z","shell.execute_reply.started":"2024-02-29T08:07:56.082969Z","shell.execute_reply":"2024-02-29T08:07:56.197928Z"},"trusted":true},"execution_count":14,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43my_batch\u001b[49m\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mshape\n","\u001b[0;31mNameError\u001b[0m: name 'y_batch' is not defined"],"ename":"NameError","evalue":"name 'y_batch' is not defined","output_type":"error"}]},{"cell_type":"code","source":"n_embed = 64\ntimesteps = padded.shape[-1]\nmodel = Encoder(len(vocab) + 1, n_embed, timesteps, head_size=16, output=4)\nbatch_size = 32\nbatch_per_epoch = padded.shape[0] // batch_size\n\n# loss_function = nn.BCELoss()\nloss_function = nn.CrossEntropyLoss()\nlearning_rate = 0.001 \noptimizer = optim.Adam(model.parameters(), lr=learning_rate)\n\n# Set the device (CPU or GPU)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\noutput_y = output_y.type(torch.LongTensor)\ninputs, targets, masked_reshape = padded.to(device), output_y.to(device), masked_reshape.to(device)\n\nfor epoch in range(10):\n    for i in range(batch_per_epoch):\n        start = i * batch_size\n        x_batch, y_batch, mask = inputs[start:start+batch_size], targets[start:start+batch_size], masked_reshape[start:start+batch_size]\n\n        model.train()\n\n        optimizer.zero_grad()\n        output = model(x_batch, mask)\n#         print(f'Shape of output from model is {output.shape} and {y_batch.shape}')\n        loss = loss_function(output, y_batch.view(-1))\n        print(f'Epoch {epoch}: {loss}')\n        loss.backward()\n        optimizer.step()\n        break","metadata":{"execution":{"iopub.status.busy":"2024-02-29T08:13:41.752519Z","iopub.execute_input":"2024-02-29T08:13:41.752894Z","iopub.status.idle":"2024-02-29T08:13:42.668868Z","shell.execute_reply.started":"2024-02-29T08:13:41.752863Z","shell.execute_reply":"2024-02-29T08:13:42.667963Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"Epoch 0: 1.3055124282836914\nEpoch 1: 5.789517402648926\nEpoch 2: 0.9687484502792358\nEpoch 3: 0.2376822680234909\nEpoch 4: 0.007536314427852631\nEpoch 5: 1.0610582828521729\nEpoch 6: 0.2768453061580658\nEpoch 7: 0.019311415031552315\nEpoch 8: 5.178110882297915e-07\nEpoch 9: 0.0\n","output_type":"stream"}]},{"cell_type":"code","source":"nested_list = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\nflattened_list = sum(nested_list, [])\nprint(flattened_list)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}