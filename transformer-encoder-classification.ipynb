{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":3176,"sourceType":"datasetVersion","datasetId":1835},{"sourceId":2510329,"sourceType":"datasetVersion","datasetId":1520310}],"dockerImageVersionId":30648,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch\nimport string\nimport re\nfrom torchtext.data.utils import get_tokenizer\nfrom torch.nn.utils.rnn import pad_sequence\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.nn import functional as F\nfrom sklearn.preprocessing import LabelEncoder\nfrom torchtext.vocab import build_vocab_from_iterator","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-03T17:44:22.244378Z","iopub.execute_input":"2024-03-03T17:44:22.244740Z","iopub.status.idle":"2024-03-03T17:44:29.206660Z","shell.execute_reply.started":"2024-03-03T17:44:22.244693Z","shell.execute_reply":"2024-03-03T17:44:29.205696Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"execution":{"iopub.status.busy":"2024-03-03T17:44:29.208306Z","iopub.execute_input":"2024-03-03T17:44:29.208752Z","iopub.status.idle":"2024-03-03T17:44:29.261421Z","shell.execute_reply.started":"2024-03-03T17:44:29.208725Z","shell.execute_reply":"2024-03-03T17:44:29.260537Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"cell_type":"code","source":"training_df = pd.read_csv('/kaggle/input/twitter-entity-sentiment-analysis/twitter_training.csv', header=None)\nvalidation_df = pd.read_csv('/kaggle/input/twitter-entity-sentiment-analysis/twitter_validation.csv', header=None)\ntraining_df.shape, validation_df.shape","metadata":{"execution":{"iopub.status.busy":"2024-03-03T17:44:29.262439Z","iopub.execute_input":"2024-03-03T17:44:29.262727Z","iopub.status.idle":"2024-03-03T17:44:29.577127Z","shell.execute_reply.started":"2024-03-03T17:44:29.262702Z","shell.execute_reply":"2024-03-03T17:44:29.575995Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"((74682, 4), (1000, 4))"},"metadata":{}}]},{"cell_type":"code","source":"print(f'Shape before dropping nulls {training_df.shape}')\ntraining_df = training_df.dropna()\nvalidation_df = validation_df.dropna()\nprint(f'Shape after dropping nulls {training_df.shape}')","metadata":{"execution":{"iopub.status.busy":"2024-03-03T17:44:29.579756Z","iopub.execute_input":"2024-03-03T17:44:29.580063Z","iopub.status.idle":"2024-03-03T17:44:29.617082Z","shell.execute_reply.started":"2024-03-03T17:44:29.580037Z","shell.execute_reply":"2024-03-03T17:44:29.616162Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Shape before dropping nulls (74682, 4)\nShape after dropping nulls (73996, 4)\n","output_type":"stream"}]},{"cell_type":"code","source":"validation_df.loc[:, 3] = validation_df.loc[:, 3].str.replace(re.escape(string.punctuation), ' ', regex=True)\nvalidation_df.loc[:, 3] = validation_df.loc[:, 3].str.replace(',', ' ', regex=True)\n\nvalidation_df.loc[:, 3] = validation_df.loc[:, 3].str.replace(re.escape(string.punctuation), ' ', regex=True)\nvalidation_df.loc[:, 3] = validation_df.loc[:, 3].str.replace(',', ' ', regex=True)","metadata":{"execution":{"iopub.status.busy":"2024-03-03T17:44:29.618402Z","iopub.execute_input":"2024-03-03T17:44:29.618711Z","iopub.status.idle":"2024-03-03T17:44:29.637648Z","shell.execute_reply.started":"2024-03-03T17:44:29.618686Z","shell.execute_reply":"2024-03-03T17:44:29.636653Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"tokenizer = get_tokenizer('basic_english')\n\ndef yield_tokens(data):\n    for text in data:\n        yield tokenizer(text)","metadata":{"execution":{"iopub.status.busy":"2024-03-03T17:44:29.638860Z","iopub.execute_input":"2024-03-03T17:44:29.639206Z","iopub.status.idle":"2024-03-03T17:44:29.643858Z","shell.execute_reply.started":"2024-03-03T17:44:29.639176Z","shell.execute_reply":"2024-03-03T17:44:29.642920Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"training_texts = training_df[3].tolist()\nval_texts = validation_df[3].tolist()\n\nvocab = build_vocab_from_iterator(yield_tokens(training_texts+val_texts), specials=['<unk>'])\nvocab.set_default_index(vocab['<unk>'])\ntext_pipeline = lambda x: vocab(tokenizer(x))\n(text_pipeline('im happy'))\n\n","metadata":{"execution":{"iopub.status.busy":"2024-03-03T17:44:29.644972Z","iopub.execute_input":"2024-03-03T17:44:29.645315Z","iopub.status.idle":"2024-03-03T17:44:31.568835Z","shell.execute_reply.started":"2024-03-03T17:44:29.645291Z","shell.execute_reply":"2024-03-03T17:44:31.567810Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"[313, 189]"},"metadata":{}}]},{"cell_type":"code","source":"int_training_texts = list(map(text_pipeline, training_texts))\nint_val_texts = list(map(text_pipeline, val_texts))\n\nprint(list(map(len, [int_training_texts, int_val_texts])))","metadata":{"execution":{"iopub.status.busy":"2024-03-03T17:44:31.570049Z","iopub.execute_input":"2024-03-03T17:44:31.570352Z","iopub.status.idle":"2024-03-03T17:44:33.640860Z","shell.execute_reply.started":"2024-03-03T17:44:31.570328Z","shell.execute_reply":"2024-03-03T17:44:33.639888Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"[73996, 1000]\n","output_type":"stream"}]},{"cell_type":"code","source":"le = LabelEncoder()\nle.fit(training_df[2])\n\ntraining_df['Labels']  = le.transform(training_df[2])\ntraining_output_y = training_df['Labels'].tolist()\n\nvalidation_df['Labels']  = le.transform(validation_df[2])\nvalidation_output_y = validation_df['Labels'].tolist()","metadata":{"execution":{"iopub.status.busy":"2024-03-03T17:44:33.642021Z","iopub.execute_input":"2024-03-03T17:44:33.642294Z","iopub.status.idle":"2024-03-03T17:44:33.671042Z","shell.execute_reply.started":"2024-03-03T17:44:33.642271Z","shell.execute_reply":"2024-03-03T17:44:33.670137Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# # Read glove embeddings\n# glove_path = '/kaggle/input/glove-global-vectors-for-word-representation/glove.6B.100d.txt'\n\n# with open(glove_path, 'r') as file:\n#      lines = file.readlines()\n\n# print(len(lines))","metadata":{"execution":{"iopub.status.busy":"2024-03-03T17:44:33.675613Z","iopub.execute_input":"2024-03-03T17:44:33.675896Z","iopub.status.idle":"2024-03-03T17:44:33.685416Z","shell.execute_reply.started":"2024-03-03T17:44:33.675856Z","shell.execute_reply":"2024-03-03T17:44:33.684623Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# word_to_vec = dict()\n# for line in lines:\n#     word_and_vec = line.split(' ', maxsplit=1)\n#     word, vec = word_and_vec[0], word_and_vec[1]\n#     vec_array = np.fromstring(vec, sep=' ').astype('float32')\n#     word_to_vec[word] = vec_array\n","metadata":{"execution":{"iopub.status.busy":"2024-03-03T17:44:33.686504Z","iopub.execute_input":"2024-03-03T17:44:33.686829Z","iopub.status.idle":"2024-03-03T17:44:33.696775Z","shell.execute_reply.started":"2024-03-03T17:44:33.686797Z","shell.execute_reply":"2024-03-03T17:44:33.695906Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def padded_and_convert(tokens, output):\n#     encode_text = lambda x: [word_to_id[_] for _ in x]\n\n#     encoded_inputs = list(map(encode_text, tokens))\n    padded = pad_sequence(list(map(torch.tensor, tokens)), batch_first=True)\n    output_y = torch.tensor(output, dtype=torch.float32).unsqueeze(-1)\n    output_y = output_y.type(torch.LongTensor)\n    print(padded.shape, output_y.shape)\n    \n    return padded, output_y\n\ntrain_padded, train_y = padded_and_convert(int_training_texts, training_output_y)\nval_padded, val_y = padded_and_convert(int_val_texts, validation_output_y )\n\nmax_sequence_length = max(max(len(seq) for seq in train_padded), max(len(seq) for seq in val_padded))\nprint(max_sequence_length)\n\ntrain_padded = pad_sequence([torch.cat([seq, torch.zeros(max_sequence_length - len(seq))]) for seq in train_padded], batch_first=True)\nval_padded = pad_sequence([torch.cat([seq, torch.zeros(max_sequence_length - len(seq))]) for seq in val_padded], batch_first=True)\nprint(train_padded.shape, val_padded.shape)","metadata":{"execution":{"iopub.status.busy":"2024-03-03T17:44:33.697994Z","iopub.execute_input":"2024-03-03T17:44:33.698318Z","iopub.status.idle":"2024-03-03T17:44:37.722636Z","shell.execute_reply.started":"2024-03-03T17:44:33.698288Z","shell.execute_reply":"2024-03-03T17:44:37.721628Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"torch.Size([73996, 311]) torch.Size([73996, 1])\ntorch.Size([1000, 73]) torch.Size([1000, 1])\n311\ntorch.Size([73996, 311]) torch.Size([1000, 311])\n","output_type":"stream"}]},{"cell_type":"code","source":"def get_masks(padded):\n    B, T = padded.shape\n    mask = torch.eq(padded, 0).to(torch.float32)\n    mask = mask * -1e9\n    masked_reshape = mask.reshape(B, 1, T)\n    return masked_reshape\n\ntrain_mask = get_masks(train_padded)\nval_mask = get_masks(val_padded)\nprint(train_mask.shape, val_mask.shape)","metadata":{"execution":{"iopub.status.busy":"2024-03-03T17:44:37.723772Z","iopub.execute_input":"2024-03-03T17:44:37.724127Z","iopub.status.idle":"2024-03-03T17:44:37.827005Z","shell.execute_reply.started":"2024-03-03T17:44:37.724100Z","shell.execute_reply":"2024-03-03T17:44:37.825932Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"torch.Size([73996, 1, 311]) torch.Size([1000, 1, 311])\n","output_type":"stream"}]},{"cell_type":"code","source":"def get_angle(timesteps, dim):\n    k = np.arange(dim)[np.newaxis, :]\n    i = k // 2\n\n    positions = np.arange(timesteps)[:, np.newaxis]\n    angles = positions / (10000 ** (2*i/dim))\n\n    return angles\n\ndef get_positional_embeddings(angles):\n    angles[:, 0::2] = np.sin(angles[:, 0::2])\n    angles[:, 1::2] = np.cos(angles[:, 1::2])\n\n    return torch.tensor(angles, dtype=torch.float32)\nn_embed = 64\ntimesteps = train_padded.shape[-1]\nprint(timesteps)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-03T17:44:37.828186Z","iopub.execute_input":"2024-03-03T17:44:37.828471Z","iopub.status.idle":"2024-03-03T17:44:37.836904Z","shell.execute_reply.started":"2024-03-03T17:44:37.828448Z","shell.execute_reply":"2024-03-03T17:44:37.835936Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"311\n","output_type":"stream"}]},{"cell_type":"code","source":"class Embedding(nn.Module):\n    def __init__(self, n_vocab, n_embed):\n        super().__init__()\n        self.embedding_layer = nn.Embedding(n_vocab, n_embed)\n        \n    def forward(self, x):\n        return self.embedding_layer(x)","metadata":{"execution":{"iopub.status.busy":"2024-03-03T17:44:37.838097Z","iopub.execute_input":"2024-03-03T17:44:37.838410Z","iopub.status.idle":"2024-03-03T17:44:37.845735Z","shell.execute_reply.started":"2024-03-03T17:44:37.838381Z","shell.execute_reply":"2024-03-03T17:44:37.844984Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"class Head(nn.Module):\n    def __init__(self, head_size=16):\n        super().__init__()\n        self.query = nn.Linear(n_embed, head_size)\n        self.key = nn.Linear(n_embed, head_size)\n        self.value = nn.Linear(n_embed, head_size)\n        \n    def forward(self, x, mask):\n        B, T, C = x.shape\n        \n        query = self.query(x)\n        key = self.key(x)\n        value = self.value(x)\n        \n        wei = query @ key.transpose(-2, -1)\n        \n        if mask is not None:\n            wei = wei + mask\n        \n        wei = F.softmax(wei, dim=-1)\n        out = wei @ value # (B, T, head_size)\n        \n        return out","metadata":{"execution":{"iopub.status.busy":"2024-03-03T17:44:37.846712Z","iopub.execute_input":"2024-03-03T17:44:37.846995Z","iopub.status.idle":"2024-03-03T17:44:37.856862Z","shell.execute_reply.started":"2024-03-03T17:44:37.846963Z","shell.execute_reply":"2024-03-03T17:44:37.855919Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# I expect n_embed output from Multi Head Attention\nclass FeedForward(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.layer1 = nn.Linear(n_embed, n_embed*4)\n        self.layer2 = nn.Linear(n_embed*4, n_embed)\n        self.relu = nn.ReLU()\n        \n    def forward(self, x):\n        out = self.layer1(x)\n        out = self.relu(out)\n        out = self.layer2(out)\n        \n        return out","metadata":{"execution":{"iopub.status.busy":"2024-03-03T17:44:37.857936Z","iopub.execute_input":"2024-03-03T17:44:37.858200Z","iopub.status.idle":"2024-03-03T17:44:37.866998Z","shell.execute_reply.started":"2024-03-03T17:44:37.858178Z","shell.execute_reply":"2024-03-03T17:44:37.866262Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# word embedding and output dimension from multihead attention are same.  \n# If I have 8 heads, the dimension of query, key and value are, let's say, 800\n# then the head_size for each head will be 800 // 8 = 100\nclass MultiHeadAttention(nn.Module):\n    def __init__(self, num_heads, n_embed):\n        super().__init__()\n        head_size = n_embed // num_heads\n        print(f'Size of embedding is {n_embed}, number of heads is {num_heads}, so head_size is {head_size}')\n        self.mha = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n        self.proj = nn.Linear(n_embed, n_embed)\n        \n    def forward(self, x, mask):\n        out = torch.cat([h(x, mask) for h in self.mha], dim=-1)\n#         print(out.shape)\n        out = self.proj(out)\n        return out","metadata":{"execution":{"iopub.status.busy":"2024-03-03T17:44:37.868023Z","iopub.execute_input":"2024-03-03T17:44:37.868289Z","iopub.status.idle":"2024-03-03T17:44:37.882152Z","shell.execute_reply.started":"2024-03-03T17:44:37.868267Z","shell.execute_reply":"2024-03-03T17:44:37.881299Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"class Block(nn.Module):\n    def __init__(self, ):\n        super().__init__()\n        self.mha = MultiHeadAttention(num_heads=4, n_embed=64)\n        self.ffw = FeedForward()\n        \n    def forward(self, x, mask):\n        out = self.mha(x, mask)\n        out = self.ffw(out)\n        \n        return out","metadata":{"execution":{"iopub.status.busy":"2024-03-03T17:44:37.883221Z","iopub.execute_input":"2024-03-03T17:44:37.883580Z","iopub.status.idle":"2024-03-03T17:44:37.891101Z","shell.execute_reply.started":"2024-03-03T17:44:37.883557Z","shell.execute_reply":"2024-03-03T17:44:37.890355Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"n_vocab = vocab.get_itos().__len__()\ne = Embedding(n_vocab, n_embed)\nx = e(train_padded[:2].to(torch.long))\nout = nn.Linear(311*64, 4)\nprint(x.shape)\nb = Block()\nout(b(x, train_mask[:2]).view(2, -1))","metadata":{"execution":{"iopub.status.busy":"2024-03-03T17:44:37.892207Z","iopub.execute_input":"2024-03-03T17:44:37.892496Z","iopub.status.idle":"2024-03-03T17:44:38.061341Z","shell.execute_reply.started":"2024-03-03T17:44:37.892471Z","shell.execute_reply":"2024-03-03T17:44:38.060500Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"torch.Size([2, 311, 64])\nSize of embedding is 64, number of heads is 4, so head_size is 16\n","output_type":"stream"},{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"tensor([[ 0.0271,  0.0075, -0.0280, -0.0075],\n        [ 0.0276, -0.0112, -0.0006, -0.0252]], grad_fn=<AddmmBackward0>)"},"metadata":{}}]},{"cell_type":"code","source":"class Encoder(nn.Module):\n    def __init__(self, n_vocab, n_embed, timesteps, head_size, output):\n        super().__init__() # What happens if I pass the class name in super?\n        self.embedding = Embedding(n_vocab, n_embed)\n#         self.sa = Head(head_size)\n        self.block = Block()\n        self.output = nn.Linear(timesteps*head_size, output)\n        \n    def forward(self, x, mask, positional_encoding):\n        B, T = x.shape # validation shape --> (1000, 73)\n#         print(self.embedding(x).shape, positional_encoding.shape)\n        embedding = self.embedding(x) + positional_encoding # (B, timesteps, n_embed) # validation: (1000, 73, 64)\n        sa_out = self.block(embedding, mask) # (B, timesteps, head_size) # validation: (1000, 73, 16)\n#         inter1 = self.inter1_layer(sa_out) # (B, timesteps, head_size) @ (head_size, timesteps) --> (B, timesteps, timesteps)\n        output = self.output(sa_out.view(B, -1))\n#         output = F.softmax(output, dim=-1)\n        \n        return output","metadata":{"execution":{"iopub.status.busy":"2024-03-03T17:44:38.062343Z","iopub.execute_input":"2024-03-03T17:44:38.062598Z","iopub.status.idle":"2024-03-03T17:44:38.069755Z","shell.execute_reply.started":"2024-03-03T17:44:38.062576Z","shell.execute_reply":"2024-03-03T17:44:38.068911Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"def train_epoch(x_batch, mask, y_batch, positional_encoding):\n    optimizer.zero_grad()\n    output = model(x_batch, mask, positional_encoding)\n    outputs = F.softmax(output, dim=-1)\n    \n    loss = loss_function(output, y_batch.view(-1))\n    \n    correct = 0\n    correct += (torch.argmax(outputs, dim=-1, keepdims=True) == y_batch).float().sum()\n    accuracy = correct / y_batch.shape[0]\n\n    loss.backward()\n    optimizer.step()\n    \n    return loss, accuracy","metadata":{"execution":{"iopub.status.busy":"2024-03-03T17:44:38.071200Z","iopub.execute_input":"2024-03-03T17:44:38.071780Z","iopub.status.idle":"2024-03-03T17:44:38.083538Z","shell.execute_reply.started":"2024-03-03T17:44:38.071750Z","shell.execute_reply":"2024-03-03T17:44:38.082629Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"train_padded, train_y = train_padded.to(device).long(), train_y.to(device)\nval_padded, val_y = val_padded.to(device).long(), val_y.to(device) \ntrain_mask, val_mask = train_mask.to(device), val_mask.to(device)\ntrain_positional_encoding = get_positional_embeddings(get_angle(timesteps, n_embed)).to(device)\nval_positional_encoding = get_positional_embeddings(get_angle(val_padded.shape[-1], n_embed)).to(device)\nprint('Shape of encodings are', train_positional_encoding.shape, val_positional_encoding.shape)\n\nn_embed = 64\ntimesteps = train_padded.shape[-1]\nmodel = Encoder(vocab.get_itos().__len__(), n_embed, timesteps, head_size=64, output=4)\nbatch_size = 64\nbatch_per_epoch = train_padded.shape[0] // batch_size\n\n# loss_function = nn.BCELoss()\nloss_function = nn.CrossEntropyLoss()\nlearning_rate = 0.001 \noptimizer = optim.Adam(model.parameters(), lr=learning_rate)\n\n# Set the device (CPU or GPU)\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-03-03T17:44:38.084677Z","iopub.execute_input":"2024-03-03T17:44:38.085112Z","iopub.status.idle":"2024-03-03T17:44:40.584135Z","shell.execute_reply.started":"2024-03-03T17:44:38.085080Z","shell.execute_reply":"2024-03-03T17:44:40.583256Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Shape of encodings are torch.Size([311, 64]) torch.Size([311, 64])\nSize of embedding is 64, number of heads is 4, so head_size is 16\n","output_type":"stream"},{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"Encoder(\n  (embedding): Embedding(\n    (embedding_layer): Embedding(43587, 64)\n  )\n  (block): Block(\n    (mha): MultiHeadAttention(\n      (mha): ModuleList(\n        (0-3): 4 x Head(\n          (query): Linear(in_features=64, out_features=16, bias=True)\n          (key): Linear(in_features=64, out_features=16, bias=True)\n          (value): Linear(in_features=64, out_features=16, bias=True)\n        )\n      )\n      (proj): Linear(in_features=64, out_features=64, bias=True)\n    )\n    (ffw): FeedForward(\n      (layer1): Linear(in_features=64, out_features=256, bias=True)\n      (layer2): Linear(in_features=256, out_features=64, bias=True)\n      (relu): ReLU()\n    )\n  )\n  (output): Linear(in_features=19904, out_features=4, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"def calculate_accuracy(outputs, labels):\n    correct = 0\n    correct += (torch.argmax(F.softmax(outputs, dim=-1), dim=-1, keepdims=True) == labels).float().sum()\n    return correct / labels.shape[0]","metadata":{"execution":{"iopub.status.busy":"2024-03-03T17:44:40.585325Z","iopub.execute_input":"2024-03-03T17:44:40.585804Z","iopub.status.idle":"2024-03-03T17:44:40.590727Z","shell.execute_reply.started":"2024-03-03T17:44:40.585777Z","shell.execute_reply":"2024-03-03T17:44:40.589810Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"\n# model = torch.nn.DataParallel(model, device_ids = [0,1]).to(device)\n# output_y = output_y.type(torch.LongTensor)\n# inputs, targets, masked_reshape = padded.to(device), output_y.to(device), masked_reshape.to(device)\n\nfor epoch in range(21, 41):\n    train_loss, val_loss = 0, 0\n    training_accuracy = 0\n    for i in range(batch_per_epoch):\n        start = i * batch_size\n        x_batch, y_batch, mask = train_padded[start:start+batch_size], train_y[start:start+batch_size], train_mask[start:start+batch_size]\n#         x_batch, y_batch, mask = x_batch.to(device).long(), y_batch.to(device).long(), mask.to(device).long()\n\n        model.train(True)\n        loss, accuracy = train_epoch(x_batch, mask, y_batch, train_positional_encoding)\n        train_loss += loss\n        training_accuracy += accuracy\n        \n    print(f'Epoch {epoch} Loss: {train_loss / (i+1)}')\n    print(f'Accuracy at Epoch {epoch} is {training_accuracy / (batch_per_epoch)}')\n    print('\\n')\n    \n    model.eval()\n    with torch.no_grad():\n        output_val = model(val_padded, val_mask, val_positional_encoding)\n        loss_val = loss_function(output_val, val_y.view(-1))\n        \n        outputs_val = F.softmax(output_val, dim=-1)\n        accuracy = calculate_accuracy(outputs_val, val_y)\n        \n        print(f'Epoch {epoch} Val loss: {loss_val}')\n        print(f'Accuracy at Epoch {epoch} is {accuracy}')\n        \n    print()","metadata":{"execution":{"iopub.status.busy":"2024-03-03T17:51:12.149834Z","iopub.execute_input":"2024-03-03T17:51:12.150585Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 21 Loss: 0.17153874039649963\nAccuracy at Epoch 21 is 0.9347696900367737\n\n\nEpoch 21 Val loss: 1.3473796844482422\nAccuracy at Epoch 21 is 0.7800000309944153\n\nEpoch 22 Loss: 0.16457676887512207\nAccuracy at Epoch 22 is 0.9370675086975098\n\n\nEpoch 22 Val loss: 1.3463139533996582\nAccuracy at Epoch 22 is 0.8100000619888306\n\nEpoch 23 Loss: 0.16395629942417145\nAccuracy at Epoch 23 is 0.9374054074287415\n\n\nEpoch 23 Val loss: 1.325027585029602\nAccuracy at Epoch 23 is 0.8110000491142273\n\nEpoch 24 Loss: 0.15521062910556793\nAccuracy at Epoch 24 is 0.9395139813423157\n\n\nEpoch 24 Val loss: 1.477818489074707\nAccuracy at Epoch 24 is 0.8060000538825989\n\nEpoch 25 Loss: 0.14966003596782684\nAccuracy at Epoch 25 is 0.942636251449585\n\n\nEpoch 25 Val loss: 1.273161768913269\nAccuracy at Epoch 25 is 0.8160000443458557\n\nEpoch 26 Loss: 0.1410703808069229\nAccuracy at Epoch 26 is 0.9464073777198792\n\n\nEpoch 26 Val loss: 1.315171480178833\nAccuracy at Epoch 26 is 0.8330000638961792\n\nEpoch 27 Loss: 0.14596439898014069\nAccuracy at Epoch 27 is 0.9441906809806824\n\n\nEpoch 27 Val loss: 1.5197075605392456\nAccuracy at Epoch 27 is 0.8160000443458557\n\nEpoch 28 Loss: 0.13255296647548676\nAccuracy at Epoch 28 is 0.949232280254364\n\n\nEpoch 28 Val loss: 1.1706750392913818\nAccuracy at Epoch 28 is 0.8360000252723694\n\nEpoch 29 Loss: 0.1273794174194336\nAccuracy at Epoch 29 is 0.9505163431167603\n\n\nEpoch 29 Val loss: 1.2786705493927002\nAccuracy at Epoch 29 is 0.8380000591278076\n\nEpoch 30 Loss: 0.12332693487405777\nAccuracy at Epoch 30 is 0.9516111612319946\n\n\nEpoch 30 Val loss: 1.272702932357788\nAccuracy at Epoch 30 is 0.8400000333786011\n\nEpoch 31 Loss: 0.1175302192568779\nAccuracy at Epoch 31 is 0.9532061219215393\n\n\nEpoch 31 Val loss: 1.2241305112838745\nAccuracy at Epoch 31 is 0.8530000448226929\n\nEpoch 32 Loss: 0.11362713575363159\nAccuracy at Epoch 32 is 0.9543415307998657\n\n\nEpoch 32 Val loss: 1.194108247756958\nAccuracy at Epoch 32 is 0.8580000400543213\n\nEpoch 33 Loss: 0.10895909368991852\nAccuracy at Epoch 33 is 0.9567339420318604\n\n\nEpoch 33 Val loss: 1.2107203006744385\nAccuracy at Epoch 33 is 0.8710000514984131\n\nEpoch 34 Loss: 0.11133792251348495\nAccuracy at Epoch 34 is 0.9563959836959839\n\n\nEpoch 34 Val loss: 1.1939576864242554\nAccuracy at Epoch 34 is 0.8530000448226929\n\nEpoch 35 Loss: 0.10603772103786469\nAccuracy at Epoch 35 is 0.9571799635887146\n\n\nEpoch 35 Val loss: 1.3609328269958496\nAccuracy at Epoch 35 is 0.8610000610351562\n\nEpoch 36 Loss: 0.10557148605585098\nAccuracy at Epoch 36 is 0.9574232697486877\n\n\nEpoch 36 Val loss: 1.0963263511657715\nAccuracy at Epoch 36 is 0.8760000467300415\n\nEpoch 37 Loss: 0.09900005906820297\nAccuracy at Epoch 37 is 0.9602481722831726\n\n\nEpoch 37 Val loss: 1.2833294868469238\nAccuracy at Epoch 37 is 0.8640000224113464\n\n","output_type":"stream"}]},{"cell_type":"code","source":"output = model(x_batch, mask, train_positional_encoding)\nprint(F.softmax(output[10], dim=-1))\ntorch.argmax(F.softmax(output[10], dim=-1)), y_batch[10]","metadata":{"execution":{"iopub.status.busy":"2024-03-03T17:47:57.773045Z","iopub.execute_input":"2024-03-03T17:47:57.773450Z","iopub.status.idle":"2024-03-03T17:47:57.956728Z","shell.execute_reply.started":"2024-03-03T17:47:57.773413Z","shell.execute_reply":"2024-03-03T17:47:57.955857Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"tensor([1.1495e-05, 6.0458e-09, 2.8058e-04, 9.9971e-01], device='cuda:0',\n       grad_fn=<SoftmaxBackward0>)\n","output_type":"stream"},{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"(tensor(3, device='cuda:0'), tensor([3], device='cuda:0'))"},"metadata":{}}]},{"cell_type":"code","source":"calculate_accuracy(output, y_batch)","metadata":{"execution":{"iopub.status.busy":"2024-03-03T17:47:57.957736Z","iopub.execute_input":"2024-03-03T17:47:57.958010Z","iopub.status.idle":"2024-03-03T17:47:57.964814Z","shell.execute_reply.started":"2024-03-03T17:47:57.957988Z","shell.execute_reply":"2024-03-03T17:47:57.964012Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"tensor(0.9219, device='cuda:0')"},"metadata":{}}]},{"cell_type":"code","source":"nested_list = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\nflattened_list = sum(nested_list, [])\nprint(flattened_list)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-03T17:47:57.969541Z","iopub.execute_input":"2024-03-03T17:47:57.970156Z","iopub.status.idle":"2024-03-03T17:47:57.975808Z","shell.execute_reply.started":"2024-03-03T17:47:57.970120Z","shell.execute_reply":"2024-03-03T17:47:57.975080Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"[1, 2, 3, 4, 5, 6, 7, 8, 9]\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}