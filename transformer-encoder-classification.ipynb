{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":2510329,"sourceType":"datasetVersion","datasetId":1520310}],"dockerImageVersionId":30648,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch\nimport string\nimport re\nfrom torchtext.data.utils import get_tokenizer\nfrom torch.nn.utils.rnn import pad_sequence\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.nn import functional as F","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-02-28T16:35:26.643567Z","iopub.execute_input":"2024-02-28T16:35:26.643932Z","iopub.status.idle":"2024-02-28T16:35:26.649701Z","shell.execute_reply.started":"2024-02-28T16:35:26.643904Z","shell.execute_reply":"2024-02-28T16:35:26.648706Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"training_df = pd.read_csv('/kaggle/input/twitter-entity-sentiment-analysis/twitter_training.csv', header=None)\ntraining_df.shape","metadata":{"execution":{"iopub.status.busy":"2024-02-27T14:06:08.496487Z","iopub.execute_input":"2024-02-27T14:06:08.496862Z","iopub.status.idle":"2024-02-27T14:06:08.695890Z","shell.execute_reply.started":"2024-02-27T14:06:08.496833Z","shell.execute_reply":"2024-02-27T14:06:08.694948Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"(74682, 4)"},"metadata":{}}]},{"cell_type":"code","source":"training_df.sample(5)","metadata":{"execution":{"iopub.status.busy":"2024-02-27T14:06:11.439966Z","iopub.execute_input":"2024-02-27T14:06:11.440920Z","iopub.status.idle":"2024-02-27T14:06:11.456320Z","shell.execute_reply.started":"2024-02-27T14:06:11.440884Z","shell.execute_reply":"2024-02-27T14:06:11.455307Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"           0              1           2  \\\n65189   7964      MaddenNFL    Positive   \n68100   3663  Cyberpunk2077  Irrelevant   \n18773  12417   WorldOfCraft    Positive   \n47857   5815      HomeDepot     Neutral   \n73598   9007         Nvidia    Positive   \n\n                                                       3  \n65189                               Happy Birthday day!.  \n68100  I’m honestly not that bothered that @Cyberpunk...  \n18773  how do I tell a youtube ads not not a GamerTM ...  \n47857  If you want to inform people in the toilet at ...  \n73598                           Holy crap is killing him  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>65189</th>\n      <td>7964</td>\n      <td>MaddenNFL</td>\n      <td>Positive</td>\n      <td>Happy Birthday day!.</td>\n    </tr>\n    <tr>\n      <th>68100</th>\n      <td>3663</td>\n      <td>Cyberpunk2077</td>\n      <td>Irrelevant</td>\n      <td>I’m honestly not that bothered that @Cyberpunk...</td>\n    </tr>\n    <tr>\n      <th>18773</th>\n      <td>12417</td>\n      <td>WorldOfCraft</td>\n      <td>Positive</td>\n      <td>how do I tell a youtube ads not not a GamerTM ...</td>\n    </tr>\n    <tr>\n      <th>47857</th>\n      <td>5815</td>\n      <td>HomeDepot</td>\n      <td>Neutral</td>\n      <td>If you want to inform people in the toilet at ...</td>\n    </tr>\n    <tr>\n      <th>73598</th>\n      <td>9007</td>\n      <td>Nvidia</td>\n      <td>Positive</td>\n      <td>Holy crap is killing him</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"print(f'Shape before dropping nulls {training_df.shape}')\ntraining_df = training_df.dropna()\nprint(f'Shape after dropping nulls {training_df.shape}')","metadata":{"execution":{"iopub.status.busy":"2024-02-27T14:07:45.279661Z","iopub.execute_input":"2024-02-27T14:07:45.280007Z","iopub.status.idle":"2024-02-27T14:07:45.313337Z","shell.execute_reply.started":"2024-02-27T14:07:45.279983Z","shell.execute_reply":"2024-02-27T14:07:45.312371Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Shape before dropping nulls (74682, 4)\nShape after dropping nulls (73996, 4)\n","output_type":"stream"}]},{"cell_type":"code","source":"training_df.loc[:, 3] = training_df.loc[:, 3].str.replace(re.escape(string.punctuation), '', regex=True)","metadata":{"execution":{"iopub.status.busy":"2024-02-27T14:13:36.664796Z","iopub.execute_input":"2024-02-27T14:13:36.665553Z","iopub.status.idle":"2024-02-27T14:13:36.730452Z","shell.execute_reply.started":"2024-02-27T14:13:36.665525Z","shell.execute_reply":"2024-02-27T14:13:36.729733Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# input_texts = training_df[3].tolist()\n# print(len(input_texts))\n\ntokenizer = get_tokenizer('basic_english')\n# tokenized_texts = [tokenizer(text) for text in input_texts]","metadata":{"execution":{"iopub.status.busy":"2024-02-28T15:45:14.992796Z","iopub.execute_input":"2024-02-28T15:45:14.993531Z","iopub.status.idle":"2024-02-28T15:45:14.997531Z","shell.execute_reply.started":"2024-02-28T15:45:14.993499Z","shell.execute_reply":"2024-02-28T15:45:14.996616Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"input_x = ['I loved the movie', 'The product exceeded my expectations', 'The service was terrible', 'The performance of the device is disappointing']\noutput_y = [1, 1, 0, 0]\n\ninput_x = list(map(str.lower, input_x))\ntokenized_inputs = [tokenizer(text) for text in input_x]\nflattened_list = sum(tokenized_inputs, [])\nprint(flattened_list)\nvocab = sorted(list(set(flattened_list)))\nword_to_id = {word:i+1 for i, word in enumerate(vocab)}\nid_to_word = {i+1:word for i, word in enumerate(vocab)}","metadata":{"execution":{"iopub.status.busy":"2024-02-28T16:19:37.569050Z","iopub.execute_input":"2024-02-28T16:19:37.569979Z","iopub.status.idle":"2024-02-28T16:19:37.577779Z","shell.execute_reply.started":"2024-02-28T16:19:37.569943Z","shell.execute_reply":"2024-02-28T16:19:37.576671Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stdout","text":"['i', 'loved', 'the', 'movie', 'the', 'product', 'exceeded', 'my', 'expectations', 'the', 'service', 'was', 'terrible', 'the', 'performance', 'of', 'the', 'device', 'is', 'disappointing']\n","output_type":"stream"}]},{"cell_type":"code","source":"encode_text = lambda x: [word_to_id[_] for _ in x]\n\nencoded_inputs = list(map(encode_text, tokenized_inputs))\npadded = pad_sequence(list(map(torch.tensor, encoded_inputs)), batch_first=True)\noutput_y = torch.tensor(output_y, dtype=torch.float32).unsqueeze(-1)\npadded.shape, output_y.shape","metadata":{"execution":{"iopub.status.busy":"2024-02-28T16:19:39.289719Z","iopub.execute_input":"2024-02-28T16:19:39.290088Z","iopub.status.idle":"2024-02-28T16:19:39.299665Z","shell.execute_reply.started":"2024-02-28T16:19:39.290057Z","shell.execute_reply":"2024-02-28T16:19:39.298703Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stdout","text":"[[5, 7, 15, 8], [15, 12, 3, 9, 4], [15, 13, 16, 14], [15, 11, 10, 15, 1, 6, 2]]\n","output_type":"stream"},{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"(torch.Size([4, 7]), torch.Size([4, 1]))"},"metadata":{}}]},{"cell_type":"code","source":"padded","metadata":{"execution":{"iopub.status.busy":"2024-02-28T16:41:38.275924Z","iopub.execute_input":"2024-02-28T16:41:38.276708Z","iopub.status.idle":"2024-02-28T16:41:38.283347Z","shell.execute_reply.started":"2024-02-28T16:41:38.276674Z","shell.execute_reply":"2024-02-28T16:41:38.282566Z"},"trusted":true},"execution_count":54,"outputs":[{"execution_count":54,"output_type":"execute_result","data":{"text/plain":"tensor([[ 5,  7, 15,  8,  0,  0,  0],\n        [15, 12,  3,  9,  4,  0,  0],\n        [15, 13, 16, 14,  0,  0,  0],\n        [15, 11, 10, 15,  1,  6,  2]])"},"metadata":{}}]},{"cell_type":"code","source":"B, T = padded.shape\nmask = torch.eq(padded, 0).to(torch.float32)\nmask = mask * -1e9\nmasked_reshape = mask.reshape(B, 1, timesteps)","metadata":{"execution":{"iopub.status.busy":"2024-02-28T16:45:26.595138Z","iopub.execute_input":"2024-02-28T16:45:26.595543Z","iopub.status.idle":"2024-02-28T16:45:26.601722Z","shell.execute_reply.started":"2024-02-28T16:45:26.595511Z","shell.execute_reply":"2024-02-28T16:45:26.600661Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"class Embedding(nn.Module):\n    def __init__(self, n_vocab, n_embed):\n        super().__init__()\n        self.embedding_layer = nn.Embedding(n_vocab, n_embed)\n        \n    def forward(self, x):\n        return self.embedding_layer(x)","metadata":{"execution":{"iopub.status.busy":"2024-02-28T15:48:31.615939Z","iopub.execute_input":"2024-02-28T15:48:31.616318Z","iopub.status.idle":"2024-02-28T15:48:31.622383Z","shell.execute_reply.started":"2024-02-28T15:48:31.616287Z","shell.execute_reply":"2024-02-28T15:48:31.621230Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"class Head(nn.Module):\n    def __init__(self, head_size=16):\n        super().__init__()\n        self.query = nn.Linear(n_embed, head_size)\n        self.key = nn.Linear(n_embed, head_size)\n        self.value = nn.Linear(n_embed, head_size)\n        \n    def forward(self, x, mask):\n        B, T, C = x.shape\n        \n        query = self.query(x)\n        key = self.key(x)\n        value = self.value(x)\n        \n        wei = query @ key.transpose(-2, -1)\n        \n        if mask is not None:\n            wei = wei + mask\n        \n        wei = F.softmax(wei, dim=-1)\n        out = wei @ value # (B, T, head_size)\n        \n        return out","metadata":{"execution":{"iopub.status.busy":"2024-02-28T16:50:01.786339Z","iopub.execute_input":"2024-02-28T16:50:01.787282Z","iopub.status.idle":"2024-02-28T16:50:01.794598Z","shell.execute_reply.started":"2024-02-28T16:50:01.787248Z","shell.execute_reply":"2024-02-28T16:50:01.793721Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"code","source":"class Encoder(nn.Module):\n    def __init__(self, n_vocab, n_embed, timesteps, head_size):\n        super().__init__() # What happens if I pass the class name in super?\n        self.embedding = Embedding(n_vocab, n_embed)\n        self.sa = Head(head_size)\n        self.inter1_layer = nn.Linear(head_size, timesteps)\n        self.output = nn.Linear(timesteps**2, 1)\n        \n    def forward(self, x, mask):\n        B, T = x.shape\n        embedding = self.embedding(x) # (B, timesteps, n_embed)\n        sa_out = self.sa(embedding, mask) # (B, timesteps, head_size)\n        inter1 = self.inter1_layer(sa_out) # (B, timesteps, head_size) @ (head_size, timesteps) --> (B, timesteps, timesteps)\n        output = self.output(inter1.view(B, -1))\n        output = torch.sigmoid(output)\n        \n        return output","metadata":{"execution":{"iopub.status.busy":"2024-02-28T16:53:59.436717Z","iopub.execute_input":"2024-02-28T16:53:59.437101Z","iopub.status.idle":"2024-02-28T16:53:59.444896Z","shell.execute_reply.started":"2024-02-28T16:53:59.437068Z","shell.execute_reply":"2024-02-28T16:53:59.443885Z"},"trusted":true},"execution_count":84,"outputs":[]},{"cell_type":"code","source":"n_embed = 32\ntimesteps = padded.shape[-1]\nmodel = Encoder(len(vocab) + 1, n_embed, timesteps, head_size=16)\n\nloss_function = nn.BCELoss()\nlearning_rate = 0.001 \noptimizer = optim.Adam(model.parameters(), lr=learning_rate)\n\n# Set the device (CPU or GPU)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\nfor epoch in range(50):\n    model.train()\n    inputs, targets, masked_reshape = padded.to(device), output_y.to(device), masked_reshape.to(device)\n    optimizer.zero_grad()\n    output = model(inputs, masked_reshape)\n    loss = loss_function(output, targets)\n    print(f'Epoch {epoch}: {loss}')\n    loss.backward()\n    optimizer.step()","metadata":{"execution":{"iopub.status.busy":"2024-02-28T16:54:04.293768Z","iopub.execute_input":"2024-02-28T16:54:04.294139Z","iopub.status.idle":"2024-02-28T16:54:04.462122Z","shell.execute_reply.started":"2024-02-28T16:54:04.294107Z","shell.execute_reply":"2024-02-28T16:54:04.461196Z"},"trusted":true},"execution_count":85,"outputs":[{"name":"stdout","text":"Epoch 0: 0.7115222215652466\nEpoch 1: 0.6946083307266235\nEpoch 2: 0.6778351068496704\nEpoch 3: 0.6611291170120239\nEpoch 4: 0.6444856524467468\nEpoch 5: 0.6278667449951172\nEpoch 6: 0.6111794710159302\nEpoch 7: 0.5942966938018799\nEpoch 8: 0.5770798921585083\nEpoch 9: 0.5594139695167542\nEpoch 10: 0.5412314534187317\nEpoch 11: 0.5225162506103516\nEpoch 12: 0.5032942295074463\nEpoch 13: 0.48361754417419434\nEpoch 14: 0.4635489881038666\nEpoch 15: 0.44315290451049805\nEpoch 16: 0.4224931001663208\nEpoch 17: 0.4016406536102295\nEpoch 18: 0.3806852102279663\nEpoch 19: 0.35974377393722534\nEpoch 20: 0.3389568328857422\nEpoch 21: 0.31847116351127625\nEpoch 22: 0.2984168529510498\nEpoch 23: 0.2788921594619751\nEpoch 24: 0.2599628269672394\nEpoch 25: 0.24167224764823914\nEpoch 26: 0.22405298054218292\nEpoch 27: 0.20713363587856293\nEpoch 28: 0.19094163179397583\nEpoch 29: 0.17550377547740936\nEpoch 30: 0.1608477532863617\nEpoch 31: 0.14700400829315186\nEpoch 32: 0.1340065896511078\nEpoch 33: 0.12188851088285446\nEpoch 34: 0.11067190766334534\nEpoch 35: 0.10035780072212219\nEpoch 36: 0.0909217968583107\nEpoch 37: 0.08231864869594574\nEpoch 38: 0.07449156045913696\nEpoch 39: 0.06738093495368958\nEpoch 40: 0.06092999875545502\nEpoch 41: 0.05508705601096153\nEpoch 42: 0.0498058944940567\nEpoch 43: 0.04504457116127014\nEpoch 44: 0.04076413810253143\nEpoch 45: 0.03692702203989029\nEpoch 46: 0.03349621966481209\nEpoch 47: 0.030434969812631607\nEpoch 48: 0.027707388624548912\nEpoch 49: 0.025278735905885696\n","output_type":"stream"}]},{"cell_type":"code","source":"nested_list = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\nflattened_list = sum(nested_list, [])\nprint(flattened_list)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-27T14:25:29.726726Z","iopub.execute_input":"2024-02-27T14:25:29.727141Z","iopub.status.idle":"2024-02-27T14:25:29.733279Z","shell.execute_reply.started":"2024-02-27T14:25:29.727112Z","shell.execute_reply":"2024-02-27T14:25:29.732265Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"[1, 2, 3, 4, 5, 6, 7, 8, 9]\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}