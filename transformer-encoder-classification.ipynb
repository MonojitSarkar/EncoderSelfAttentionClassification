{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":3176,"sourceType":"datasetVersion","datasetId":1835},{"sourceId":2510329,"sourceType":"datasetVersion","datasetId":1520310}],"dockerImageVersionId":30648,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch\nimport string\nimport re\nfrom torchtext.data.utils import get_tokenizer\nfrom torch.nn.utils.rnn import pad_sequence\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.nn import functional as F\nfrom sklearn.preprocessing import LabelEncoder\nfrom torchtext.vocab import build_vocab_from_iterator","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-04T16:14:10.168944Z","iopub.execute_input":"2024-03-04T16:14:10.169273Z","iopub.status.idle":"2024-03-04T16:14:14.017456Z","shell.execute_reply.started":"2024-03-04T16:14:10.169247Z","shell.execute_reply":"2024-03-04T16:14:14.016275Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"execution":{"iopub.status.busy":"2024-03-04T16:14:14.020504Z","iopub.execute_input":"2024-03-04T16:14:14.021082Z","iopub.status.idle":"2024-03-04T16:14:14.077467Z","shell.execute_reply.started":"2024-03-04T16:14:14.021046Z","shell.execute_reply":"2024-03-04T16:14:14.076168Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"cell_type":"code","source":"training_df = pd.read_csv('/kaggle/input/twitter-entity-sentiment-analysis/twitter_training.csv', header=None)\nvalidation_df = pd.read_csv('/kaggle/input/twitter-entity-sentiment-analysis/twitter_validation.csv', header=None)\ntraining_df.shape, validation_df.shape","metadata":{"execution":{"iopub.status.busy":"2024-03-04T16:14:14.078884Z","iopub.execute_input":"2024-03-04T16:14:14.079327Z","iopub.status.idle":"2024-03-04T16:14:14.334921Z","shell.execute_reply.started":"2024-03-04T16:14:14.079286Z","shell.execute_reply":"2024-03-04T16:14:14.333819Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"((74682, 4), (1000, 4))"},"metadata":{}}]},{"cell_type":"code","source":"print(f'Shape before dropping nulls {training_df.shape}')\ntraining_df = training_df.dropna()\nvalidation_df = validation_df.dropna()\nprint(f'Shape after dropping nulls {training_df.shape}')","metadata":{"execution":{"iopub.status.busy":"2024-03-04T16:14:28.131813Z","iopub.execute_input":"2024-03-04T16:14:28.132231Z","iopub.status.idle":"2024-03-04T16:14:28.174403Z","shell.execute_reply.started":"2024-03-04T16:14:28.132183Z","shell.execute_reply":"2024-03-04T16:14:28.173373Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Shape before dropping nulls (74682, 4)\nShape after dropping nulls (73996, 4)\n","output_type":"stream"}]},{"cell_type":"code","source":"import re\n\ndef clean_text(tweet):\n    # Remove URLs\n    tweet = re.sub(r'http\\S+', '', tweet)\n    \n    # Remove mentions and hashtags\n    tweet = re.sub(r'@[A-Za-z0-9_]+|#[A-Za-z0-9_]+', '', tweet)\n    \n    # Remove special characters, numbers, and punctuation\n    tweet = re.sub(r'[^A-Za-z\\s]', '', tweet)\n    \n    # Remove 'RT' (Retweet) indicator\n    tweet = re.sub(r'\\bRT\\b', '', tweet)\n    \n    return tweet.lower()","metadata":{"execution":{"iopub.status.busy":"2024-03-04T16:14:31.541233Z","iopub.execute_input":"2024-03-04T16:14:31.542370Z","iopub.status.idle":"2024-03-04T16:14:31.548434Z","shell.execute_reply.started":"2024-03-04T16:14:31.542331Z","shell.execute_reply":"2024-03-04T16:14:31.547296Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# validation_df.loc[:, 3] = validation_df.loc[:, 3].str.replace(re.escape(string.punctuation), ' ', regex=True)\n\ntraining_df.loc[:, 3] = training_df[3].apply(clean_text)\nvalidation_df.loc[:, 3] = validation_df[3].apply(clean_text)","metadata":{"execution":{"iopub.status.busy":"2024-03-04T16:14:34.181767Z","iopub.execute_input":"2024-03-04T16:14:34.182171Z","iopub.status.idle":"2024-03-04T16:14:35.617293Z","shell.execute_reply.started":"2024-03-04T16:14:34.182141Z","shell.execute_reply":"2024-03-04T16:14:35.616166Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"tokenizer = get_tokenizer('basic_english')\n\ndef yield_tokens(data):\n    for text in data:\n        yield tokenizer(text)","metadata":{"execution":{"iopub.status.busy":"2024-03-04T16:14:38.541205Z","iopub.execute_input":"2024-03-04T16:14:38.541604Z","iopub.status.idle":"2024-03-04T16:14:38.546770Z","shell.execute_reply.started":"2024-03-04T16:14:38.541572Z","shell.execute_reply":"2024-03-04T16:14:38.545702Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"training_texts = training_df[3].tolist()\nval_texts = validation_df[3].tolist()\n\nvocab = build_vocab_from_iterator(yield_tokens(training_texts+val_texts), specials=['<unk>'])\nvocab.set_default_index(vocab['<unk>'])\ntext_pipeline = lambda x: vocab(tokenizer(x))\n(text_pipeline('im happy'))\n\n","metadata":{"execution":{"iopub.status.busy":"2024-03-04T16:14:40.111873Z","iopub.execute_input":"2024-03-04T16:14:40.112777Z","iopub.status.idle":"2024-03-04T16:14:41.773269Z","shell.execute_reply.started":"2024-03-04T16:14:40.112740Z","shell.execute_reply":"2024-03-04T16:14:41.772255Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"[30, 167]"},"metadata":{}}]},{"cell_type":"code","source":"int_training_texts = list(map(text_pipeline, training_texts))\nint_val_texts = list(map(text_pipeline, val_texts))\n\nprint(list(map(len, [int_training_texts, int_val_texts])))","metadata":{"execution":{"iopub.status.busy":"2024-03-04T16:14:43.591296Z","iopub.execute_input":"2024-03-04T16:14:43.591704Z","iopub.status.idle":"2024-03-04T16:14:45.417846Z","shell.execute_reply.started":"2024-03-04T16:14:43.591672Z","shell.execute_reply":"2024-03-04T16:14:45.416613Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"[73996, 1000]\n","output_type":"stream"}]},{"cell_type":"code","source":"le = LabelEncoder()\nle.fit(training_df[2])\n\ntraining_df['Labels']  = le.transform(training_df[2])\ntraining_output_y = training_df['Labels'].tolist()\n\nvalidation_df['Labels']  = le.transform(validation_df[2])\nvalidation_output_y = validation_df['Labels'].tolist()","metadata":{"execution":{"iopub.status.busy":"2024-03-04T16:14:45.419694Z","iopub.execute_input":"2024-03-04T16:14:45.420083Z","iopub.status.idle":"2024-03-04T16:14:45.450615Z","shell.execute_reply.started":"2024-03-04T16:14:45.420053Z","shell.execute_reply":"2024-03-04T16:14:45.449490Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# # Read glove embeddings\n# glove_path = '/kaggle/input/glove-global-vectors-for-word-representation/glove.6B.100d.txt'\n\n# with open(glove_path, 'r') as file:\n#      lines = file.readlines()\n\n# print(len(lines))","metadata":{"execution":{"iopub.status.busy":"2024-03-04T16:14:45.451855Z","iopub.execute_input":"2024-03-04T16:14:45.452185Z","iopub.status.idle":"2024-03-04T16:14:45.461763Z","shell.execute_reply.started":"2024-03-04T16:14:45.452154Z","shell.execute_reply":"2024-03-04T16:14:45.460845Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# word_to_vec = dict()\n# for line in lines:\n#     word_and_vec = line.split(' ', maxsplit=1)\n#     word, vec = word_and_vec[0], word_and_vec[1]\n#     vec_array = np.fromstring(vec, sep=' ').astype('float32')\n#     word_to_vec[word] = vec_array\n","metadata":{"execution":{"iopub.status.busy":"2024-03-04T16:14:45.610948Z","iopub.execute_input":"2024-03-04T16:14:45.611262Z","iopub.status.idle":"2024-03-04T16:14:45.615706Z","shell.execute_reply.started":"2024-03-04T16:14:45.611237Z","shell.execute_reply":"2024-03-04T16:14:45.614587Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def padded_and_convert(tokens, output):\n#     encode_text = lambda x: [word_to_id[_] for _ in x]\n\n#     encoded_inputs = list(map(encode_text, tokens))\n    padded = pad_sequence(list(map(torch.tensor, tokens)), batch_first=True)\n    output_y = torch.tensor(output, dtype=torch.float32).unsqueeze(-1)\n    output_y = output_y.type(torch.LongTensor)\n    print(padded.shape, output_y.shape)\n    \n    return padded, output_y\n\ntrain_padded, train_y = padded_and_convert(int_training_texts, training_output_y)\nval_padded, val_y = padded_and_convert(int_val_texts, validation_output_y )\n\nmax_sequence_length = max(max(len(seq) for seq in train_padded), max(len(seq) for seq in val_padded))\nprint(max_sequence_length)\n\ntrain_padded = pad_sequence([torch.cat([seq, torch.zeros(max_sequence_length - len(seq))]) for seq in train_padded], batch_first=True)\nval_padded = pad_sequence([torch.cat([seq, torch.zeros(max_sequence_length - len(seq))]) for seq in val_padded], batch_first=True)\nprint(train_padded.shape, val_padded.shape)","metadata":{"execution":{"iopub.status.busy":"2024-03-04T16:14:46.274577Z","iopub.execute_input":"2024-03-04T16:14:46.275248Z","iopub.status.idle":"2024-03-04T16:14:50.124659Z","shell.execute_reply.started":"2024-03-04T16:14:46.275218Z","shell.execute_reply":"2024-03-04T16:14:50.123159Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"torch.Size([73996, 166]) torch.Size([73996, 1])\ntorch.Size([1000, 56]) torch.Size([1000, 1])\n166\ntorch.Size([73996, 166]) torch.Size([1000, 166])\n","output_type":"stream"}]},{"cell_type":"code","source":"def get_masks(padded):\n    B, T = padded.shape\n    mask = torch.eq(padded, 0).to(torch.float32)\n    mask = mask * -1e9\n    masked_reshape = mask.reshape(B, 1, T)\n    return masked_reshape\n\ntrain_mask = get_masks(train_padded)\nval_mask = get_masks(val_padded)\nprint(train_mask.shape, val_mask.shape)","metadata":{"execution":{"iopub.status.busy":"2024-03-04T16:14:50.126436Z","iopub.execute_input":"2024-03-04T16:14:50.126770Z","iopub.status.idle":"2024-03-04T16:14:50.196620Z","shell.execute_reply.started":"2024-03-04T16:14:50.126743Z","shell.execute_reply":"2024-03-04T16:14:50.195499Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"torch.Size([73996, 1, 166]) torch.Size([1000, 1, 166])\n","output_type":"stream"}]},{"cell_type":"code","source":"def get_angle(timesteps, dim):\n    k = np.arange(dim)[np.newaxis, :]\n    i = k // 2\n\n    positions = np.arange(timesteps)[:, np.newaxis]\n    angles = positions / (10000 ** (2*i/dim))\n\n    return angles\n\ndef get_positional_embeddings(angles):\n    angles[:, 0::2] = np.sin(angles[:, 0::2])\n    angles[:, 1::2] = np.cos(angles[:, 1::2])\n\n    return torch.tensor(angles, dtype=torch.float32)\nn_embed = 64\ntimesteps = train_padded.shape[-1]\nprint(timesteps)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-04T16:14:50.197990Z","iopub.execute_input":"2024-03-04T16:14:50.198402Z","iopub.status.idle":"2024-03-04T16:14:50.206632Z","shell.execute_reply.started":"2024-03-04T16:14:50.198361Z","shell.execute_reply":"2024-03-04T16:14:50.205676Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"166\n","output_type":"stream"}]},{"cell_type":"code","source":"class Embedding(nn.Module):\n    def __init__(self, n_vocab, n_embed):\n        super().__init__()\n        self.embedding_layer = nn.Embedding(n_vocab, n_embed)\n        \n    def forward(self, x):\n        return self.embedding_layer(x)","metadata":{"execution":{"iopub.status.busy":"2024-03-04T16:14:50.208953Z","iopub.execute_input":"2024-03-04T16:14:50.209483Z","iopub.status.idle":"2024-03-04T16:14:50.217671Z","shell.execute_reply.started":"2024-03-04T16:14:50.209454Z","shell.execute_reply":"2024-03-04T16:14:50.216731Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"class Head(nn.Module):\n    def __init__(self, head_size=16):\n        super().__init__()\n        self.query = nn.Linear(n_embed, head_size)\n        self.key = nn.Linear(n_embed, head_size)\n        self.value = nn.Linear(n_embed, head_size)\n        \n    def forward(self, x, mask):\n        B, T, C = x.shape\n        \n        query = self.query(x)\n        key = self.key(x)\n        value = self.value(x)\n        \n        wei = query @ key.transpose(-2, -1)\n        \n        if mask is not None:\n            wei = wei + mask\n        \n        wei = F.softmax(wei, dim=-1)\n        out = wei @ value # (B, T, head_size)\n        \n        return out","metadata":{"execution":{"iopub.status.busy":"2024-03-04T16:14:50.219136Z","iopub.execute_input":"2024-03-04T16:14:50.219488Z","iopub.status.idle":"2024-03-04T16:14:50.230208Z","shell.execute_reply.started":"2024-03-04T16:14:50.219448Z","shell.execute_reply":"2024-03-04T16:14:50.229273Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# arr = torch.rand((2, 3, 5))\n# print(arr)\n# print(arr.permute(0, 2, 1))\n# nn.AvgPool1d(kernel_size=3)(arr.permute(0, 2, 1)).view(2, -1)","metadata":{"execution":{"iopub.status.busy":"2024-03-04T16:14:50.231579Z","iopub.execute_input":"2024-03-04T16:14:50.232376Z","iopub.status.idle":"2024-03-04T16:14:50.245799Z","shell.execute_reply.started":"2024-03-04T16:14:50.232340Z","shell.execute_reply":"2024-03-04T16:14:50.244917Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# I expect n_embed output from Multi Head Attention\nclass FeedForward(nn.Module):\n    def __init__(self, n_embed):\n        super().__init__()\n        self.layer1 = nn.Linear(n_embed, n_embed*4)\n        self.layer2 = nn.Linear(n_embed*4, n_embed)\n        self.relu = nn.ReLU()\n        \n    def forward(self, x):\n        out = self.layer1(x)\n        out = self.relu(out)\n        out = self.layer2(out)\n        \n        return out","metadata":{"execution":{"iopub.status.busy":"2024-03-04T16:14:50.247031Z","iopub.execute_input":"2024-03-04T16:14:50.247769Z","iopub.status.idle":"2024-03-04T16:14:50.256657Z","shell.execute_reply.started":"2024-03-04T16:14:50.247733Z","shell.execute_reply":"2024-03-04T16:14:50.255841Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# word embedding and output dimension from multihead attention are same.  \n# If I have 8 heads, the dimension of query, key and value are, let's say, 800\n# then the head_size for each head will be 800 // 8 = 100\nclass MultiHeadAttention(nn.Module):\n    def __init__(self, num_heads, n_embed):\n        super().__init__()\n        head_size = n_embed // num_heads\n        print(f'Size of embedding is {n_embed}, number of heads is {num_heads}, so head_size is {head_size}')\n        self.mha = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n        self.proj = nn.Linear(n_embed, n_embed)\n        \n    def forward(self, x, mask):\n        out = torch.cat([h(x, mask) for h in self.mha], dim=-1)\n#         print(out.shape)\n        out = self.proj(out)\n        return out","metadata":{"execution":{"iopub.status.busy":"2024-03-04T16:14:50.258016Z","iopub.execute_input":"2024-03-04T16:14:50.258321Z","iopub.status.idle":"2024-03-04T16:14:50.269235Z","shell.execute_reply.started":"2024-03-04T16:14:50.258276Z","shell.execute_reply":"2024-03-04T16:14:50.268378Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"class Block(nn.Module):\n    def __init__(self, num_heads, n_embed):\n        super().__init__()\n        self.mha = MultiHeadAttention(num_heads, n_embed)\n        self.ffw = FeedForward(n_embed)\n        self.ln1 = nn.LayerNorm(n_embed)\n        self.ln2 = nn.LayerNorm(n_embed)\n        \n    def forward(self, x, mask):\n#         out = self.ln1(x + self.mha(x, mask))\n#         out = self.ln2(out + self.ffw(out))\n        out = x + self.mha(self.ln1(x), mask)\n        out = out + self.ffw(self.ln2(out))\n        \n        return out","metadata":{"execution":{"iopub.status.busy":"2024-03-04T17:01:29.892889Z","iopub.execute_input":"2024-03-04T17:01:29.893263Z","iopub.status.idle":"2024-03-04T17:01:29.901193Z","shell.execute_reply.started":"2024-03-04T17:01:29.893235Z","shell.execute_reply":"2024-03-04T17:01:29.899957Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"class Encoder(nn.Module):\n    def __init__(self, n_vocab, n_embed, timesteps, output, num_heads, N):\n        super().__init__() # What happens if I pass the class name in super?\n        self.N = N\n        self.embedding = Embedding(n_vocab, n_embed)\n#         self.sa = Head(head_size)\n        self.blocks = nn.ModuleList([Block(num_heads, n_embed) for _ in range(N)])\n        self.output = nn.Linear(n_embed, output)\n        self.avgpool = nn.AvgPool1d(timesteps)\n        \n    def forward(self, x, mask, positional_encoding):\n        B, T = x.shape # validation shape --> (1000, 73)\n#         print(self.embedding(x).shape, positional_encoding.shape)\n        x = self.embedding(x) + positional_encoding # (B, timesteps, n_embed) # validation: (1000, 73, 64)\n#         sa_out = self.block1(embedding, mask) # (B, timesteps, head_size) # validation: (1000, 73, 16)\n        for _ in range(self.N):\n            x = self.blocks[_](x, mask)\n#         inter1 = self.inter1_layer(sa_out) # (B, timesteps, head_size) @ (head_size, timesteps) --> (B, timesteps, timesteps)\n#         output = self.output(sa_out.view(B, -1))\n        output = self.avgpool(x.permute(0, 2, 1)).view(B, -1)\n        output = self.output(output)\n#         output = F.softmax(output, dim=-1)\n        \n        return output","metadata":{"execution":{"iopub.status.busy":"2024-03-04T17:39:24.196423Z","iopub.execute_input":"2024-03-04T17:39:24.197041Z","iopub.status.idle":"2024-03-04T17:39:24.206213Z","shell.execute_reply.started":"2024-03-04T17:39:24.197010Z","shell.execute_reply":"2024-03-04T17:39:24.204987Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"def train_epoch(x_batch, mask, y_batch, positional_encoding):\n    optimizer.zero_grad()\n    output = model(x_batch, mask, positional_encoding)\n    outputs = F.softmax(output, dim=-1)\n    \n    loss = loss_function(output, y_batch.view(-1))\n    \n    correct = 0\n    correct += (torch.argmax(outputs, dim=-1, keepdims=True) == y_batch).float().sum()\n    accuracy = correct / y_batch.shape[0]\n\n    loss.backward()\n    optimizer.step()\n    \n    return loss, accuracy","metadata":{"execution":{"iopub.status.busy":"2024-03-04T16:14:50.295622Z","iopub.execute_input":"2024-03-04T16:14:50.295924Z","iopub.status.idle":"2024-03-04T16:14:50.304912Z","shell.execute_reply.started":"2024-03-04T16:14:50.295900Z","shell.execute_reply":"2024-03-04T16:14:50.303831Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# best achieved: n_embed=128\nn_embed = 128\ntimesteps = train_padded.shape[-1]\nbatch_size = 128\nbatch_per_epoch = train_padded.shape[0] // batch_size\n\ntrain_padded, train_y = train_padded.to(device).long(), train_y.to(device)\nval_padded, val_y = val_padded.to(device).long(), val_y.to(device) \ntrain_mask, val_mask = train_mask.to(device), val_mask.to(device)\ntrain_positional_encoding = get_positional_embeddings(get_angle(timesteps, n_embed)).to(device)\nval_positional_encoding = get_positional_embeddings(get_angle(val_padded.shape[-1], n_embed)).to(device)\nprint('Shape of encodings are', train_positional_encoding.shape, val_positional_encoding.shape)\n\n\nmodel = Encoder(vocab.get_itos().__len__(), n_embed, timesteps, output=4, num_heads=4, N=3)\n\n# loss_function = nn.BCELoss()\nloss_function = nn.CrossEntropyLoss()\nlearning_rate = 0.001 \noptimizer = optim.Adam(model.parameters(), lr=learning_rate)\n\n# Set the device (CPU or GPU)\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-03-04T17:39:27.306654Z","iopub.execute_input":"2024-03-04T17:39:27.307039Z","iopub.status.idle":"2024-03-04T17:39:27.404815Z","shell.execute_reply.started":"2024-03-04T17:39:27.307010Z","shell.execute_reply":"2024-03-04T17:39:27.403808Z"},"trusted":true},"execution_count":64,"outputs":[{"name":"stdout","text":"Shape of encodings are torch.Size([166, 128]) torch.Size([166, 128])\nSize of embedding is 128, number of heads is 4, so head_size is 32\nSize of embedding is 128, number of heads is 4, so head_size is 32\nSize of embedding is 128, number of heads is 4, so head_size is 32\n","output_type":"stream"},{"execution_count":64,"output_type":"execute_result","data":{"text/plain":"Encoder(\n  (embedding): Embedding(\n    (embedding_layer): Embedding(37545, 128)\n  )\n  (blocks): ModuleList(\n    (0-2): 3 x Block(\n      (mha): MultiHeadAttention(\n        (mha): ModuleList(\n          (0-3): 4 x Head(\n            (query): Linear(in_features=128, out_features=32, bias=True)\n            (key): Linear(in_features=128, out_features=32, bias=True)\n            (value): Linear(in_features=128, out_features=32, bias=True)\n          )\n        )\n        (proj): Linear(in_features=128, out_features=128, bias=True)\n      )\n      (ffw): FeedForward(\n        (layer1): Linear(in_features=128, out_features=512, bias=True)\n        (layer2): Linear(in_features=512, out_features=128, bias=True)\n        (relu): ReLU()\n      )\n      (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n      (ln2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n    )\n  )\n  (output): Linear(in_features=128, out_features=4, bias=True)\n  (avgpool): AvgPool1d(kernel_size=(166,), stride=(166,), padding=(0,))\n)"},"metadata":{}}]},{"cell_type":"code","source":"def calculate_accuracy(outputs, labels):\n    correct = 0\n    correct += (torch.argmax(F.softmax(outputs, dim=-1), dim=-1, keepdims=True) == labels).float().sum()\n    return correct / labels.shape[0]","metadata":{"execution":{"iopub.status.busy":"2024-03-04T16:14:51.693400Z","iopub.execute_input":"2024-03-04T16:14:51.694424Z","iopub.status.idle":"2024-03-04T16:14:51.700000Z","shell.execute_reply.started":"2024-03-04T16:14:51.694383Z","shell.execute_reply":"2024-03-04T16:14:51.699028Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"\n# model = torch.nn.DataParallel(model, device_ids = [0,1]).to(device)\n# output_y = output_y.type(torch.LongTensor)\n# inputs, targets, masked_reshape = padded.to(device), output_y.to(device), masked_reshape.to(device)\n\nfor epoch in range(0, 71):\n    train_loss, val_loss = 0, 0\n    training_accuracy = 0\n    for i in range(batch_per_epoch):\n        start = i * batch_size\n        x_batch, y_batch, mask = train_padded[start:start+batch_size], train_y[start:start+batch_size], train_mask[start:start+batch_size]\n#         x_batch, y_batch, mask = x_batch.to(device).long(), y_batch.to(device).long(), mask.to(device).long()\n\n        model.train(True)\n        loss, accuracy = train_epoch(x_batch, mask, y_batch, train_positional_encoding)\n        train_loss += loss\n        training_accuracy += accuracy\n        \n    print(f'Epoch {epoch} Loss: {train_loss / (i+1)}')\n    print(f'Accuracy at Epoch {epoch} is {training_accuracy / (batch_per_epoch)}')\n    print('\\n')\n    \n    model.eval()\n    with torch.no_grad():\n        output_val = model(val_padded, val_mask, val_positional_encoding)\n        loss_val = loss_function(output_val, val_y.view(-1))\n        \n        outputs_val = F.softmax(output_val, dim=-1)\n        accuracy = calculate_accuracy(outputs_val, val_y)\n        \n        print(f'Epoch {epoch} Val loss: {loss_val}')\n        print(f'Accuracy at Epoch {epoch} is {accuracy}')\n        \n    print()","metadata":{"execution":{"iopub.status.busy":"2024-03-04T17:39:31.216436Z","iopub.execute_input":"2024-03-04T17:39:31.216833Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 0 Loss: 1.2490170001983643\nAccuracy at Epoch 0 is 0.4451638460159302\n\n\nEpoch 0 Val loss: 1.396950602531433\nAccuracy at Epoch 0 is 0.44700002670288086\n\nEpoch 1 Loss: 1.1683626174926758\nAccuracy at Epoch 1 is 0.4966614544391632\n\n\nEpoch 1 Val loss: 1.2908085584640503\nAccuracy at Epoch 1 is 0.5180000066757202\n\nEpoch 2 Loss: 1.1056114435195923\nAccuracy at Epoch 2 is 0.5315744280815125\n\n\nEpoch 2 Val loss: 1.1997547149658203\nAccuracy at Epoch 2 is 0.5440000295639038\n\nEpoch 3 Loss: 1.0362695455551147\nAccuracy at Epoch 3 is 0.5678930878639221\n\n\nEpoch 3 Val loss: 1.166643500328064\nAccuracy at Epoch 3 is 0.6020000576972961\n\nEpoch 4 Loss: 0.9562835693359375\nAccuracy at Epoch 4 is 0.6101319193840027\n\n\nEpoch 4 Val loss: 1.0355192422866821\nAccuracy at Epoch 4 is 0.6320000290870667\n\nEpoch 5 Loss: 0.8755960464477539\nAccuracy at Epoch 5 is 0.6490592956542969\n\n\nEpoch 5 Val loss: 1.0103425979614258\nAccuracy at Epoch 5 is 0.6450000405311584\n\nEpoch 6 Loss: 0.7891126871109009\nAccuracy at Epoch 6 is 0.6912305355072021\n\n\nEpoch 6 Val loss: 0.9306296706199646\nAccuracy at Epoch 6 is 0.6840000152587891\n\nEpoch 7 Loss: 0.6857743263244629\nAccuracy at Epoch 7 is 0.7349832653999329\n\n\nEpoch 7 Val loss: 0.8580705523490906\nAccuracy at Epoch 7 is 0.706000030040741\n\nEpoch 8 Loss: 0.6016148924827576\nAccuracy at Epoch 8 is 0.77264004945755\n\n\nEpoch 8 Val loss: 0.7674878835678101\nAccuracy at Epoch 8 is 0.737000048160553\n\nEpoch 9 Loss: 0.5106346011161804\nAccuracy at Epoch 9 is 0.809053361415863\n\n\nEpoch 9 Val loss: 0.7413783073425293\nAccuracy at Epoch 9 is 0.7490000128746033\n\nEpoch 10 Loss: 0.43456411361694336\nAccuracy at Epoch 10 is 0.8383299112319946\n\n\nEpoch 10 Val loss: 0.7285352349281311\nAccuracy at Epoch 10 is 0.7710000276565552\n\nEpoch 11 Loss: 0.37060123682022095\nAccuracy at Epoch 11 is 0.8639706373214722\n\n\nEpoch 11 Val loss: 0.6227701902389526\nAccuracy at Epoch 11 is 0.8050000667572021\n\nEpoch 12 Loss: 0.3170393407344818\nAccuracy at Epoch 12 is 0.8856509923934937\n\n\nEpoch 12 Val loss: 0.6661268472671509\nAccuracy at Epoch 12 is 0.7970000505447388\n\nEpoch 13 Loss: 0.2688332200050354\nAccuracy at Epoch 13 is 0.90234375\n\n\nEpoch 13 Val loss: 0.6432914137840271\nAccuracy at Epoch 13 is 0.8110000491142273\n\nEpoch 14 Loss: 0.24920909106731415\nAccuracy at Epoch 14 is 0.9081828594207764\n\n\nEpoch 14 Val loss: 0.6037905812263489\nAccuracy at Epoch 14 is 0.8280000686645508\n\nEpoch 15 Loss: 0.22081005573272705\nAccuracy at Epoch 15 is 0.9195096492767334\n\n\nEpoch 15 Val loss: 0.5774484872817993\nAccuracy at Epoch 15 is 0.8450000286102295\n\nEpoch 16 Loss: 0.19918762147426605\nAccuracy at Epoch 16 is 0.926227331161499\n\n\nEpoch 16 Val loss: 0.5694153904914856\nAccuracy at Epoch 16 is 0.8400000333786011\n\nEpoch 17 Loss: 0.18966712057590485\nAccuracy at Epoch 17 is 0.9302011728286743\n\n\nEpoch 17 Val loss: 0.47898468375205994\nAccuracy at Epoch 17 is 0.8630000352859497\n\nEpoch 18 Loss: 0.16960930824279785\nAccuracy at Epoch 18 is 0.9369729161262512\n\n\nEpoch 18 Val loss: 0.4749056100845337\nAccuracy at Epoch 18 is 0.8800000548362732\n\nEpoch 19 Loss: 0.17645740509033203\nAccuracy at Epoch 19 is 0.9337289333343506\n\n\nEpoch 19 Val loss: 0.5212457180023193\nAccuracy at Epoch 19 is 0.8680000305175781\n\nEpoch 20 Loss: 0.15955369174480438\nAccuracy at Epoch 20 is 0.9390814304351807\n\n\nEpoch 20 Val loss: 0.43449774384498596\nAccuracy at Epoch 20 is 0.8940000534057617\n\nEpoch 21 Loss: 0.14516830444335938\nAccuracy at Epoch 21 is 0.9444339871406555\n\n\nEpoch 21 Val loss: 0.453151136636734\nAccuracy at Epoch 21 is 0.8860000371932983\n\nEpoch 22 Loss: 0.13801677525043488\nAccuracy at Epoch 22 is 0.9480428695678711\n\n\nEpoch 22 Val loss: 0.36549481749534607\nAccuracy at Epoch 22 is 0.8990000486373901\n\nEpoch 23 Loss: 0.13608503341674805\nAccuracy at Epoch 23 is 0.9482591152191162\n\n\nEpoch 23 Val loss: 0.4037415087223053\nAccuracy at Epoch 23 is 0.8980000615119934\n\nEpoch 24 Loss: 0.12828370928764343\nAccuracy at Epoch 24 is 0.950489342212677\n\n\nEpoch 24 Val loss: 0.4377882182598114\nAccuracy at Epoch 24 is 0.8970000147819519\n\nEpoch 25 Loss: 0.12513142824172974\nAccuracy at Epoch 25 is 0.9517598748207092\n\n\nEpoch 25 Val loss: 0.3691425025463104\nAccuracy at Epoch 25 is 0.9070000648498535\n\nEpoch 26 Loss: 0.11922898888587952\nAccuracy at Epoch 26 is 0.9533413052558899\n\n\nEpoch 26 Val loss: 0.3225944936275482\nAccuracy at Epoch 26 is 0.9270000457763672\n\nEpoch 27 Loss: 0.11355531960725784\nAccuracy at Epoch 27 is 0.956625759601593\n\n\nEpoch 27 Val loss: 0.3180985152721405\nAccuracy at Epoch 27 is 0.9180000424385071\n\nEpoch 28 Loss: 0.11007868498563766\nAccuracy at Epoch 28 is 0.956625759601593\n\n\nEpoch 28 Val loss: 0.33551931381225586\nAccuracy at Epoch 28 is 0.9200000166893005\n\nEpoch 29 Loss: 0.10778482258319855\nAccuracy at Epoch 29 is 0.9573286175727844\n\n\nEpoch 29 Val loss: 0.25561365485191345\nAccuracy at Epoch 29 is 0.9390000700950623\n\nEpoch 30 Loss: 0.11044997721910477\nAccuracy at Epoch 30 is 0.957071840763092\n\n\nEpoch 30 Val loss: 0.29297566413879395\nAccuracy at Epoch 30 is 0.9310000538825989\n\nEpoch 31 Loss: 0.10244963318109512\nAccuracy at Epoch 31 is 0.9593290686607361\n\n\nEpoch 31 Val loss: 0.2790117561817169\nAccuracy at Epoch 31 is 0.9310000538825989\n\nEpoch 32 Loss: 0.10296420753002167\nAccuracy at Epoch 32 is 0.9596534967422485\n\n\nEpoch 32 Val loss: 0.3610769510269165\nAccuracy at Epoch 32 is 0.9220000505447388\n\nEpoch 33 Loss: 0.09034579247236252\nAccuracy at Epoch 33 is 0.963627278804779\n\n\nEpoch 33 Val loss: 0.373926043510437\nAccuracy at Epoch 33 is 0.9240000247955322\n\nEpoch 34 Loss: 0.09880854934453964\nAccuracy at Epoch 34 is 0.9604238867759705\n\n\nEpoch 34 Val loss: 0.26108625531196594\nAccuracy at Epoch 34 is 0.940000057220459\n\nEpoch 35 Loss: 0.09191564470529556\nAccuracy at Epoch 35 is 0.9631677269935608\n\n\nEpoch 35 Val loss: 0.25793904066085815\nAccuracy at Epoch 35 is 0.9360000491142273\n\nEpoch 36 Loss: 0.086232990026474\nAccuracy at Epoch 36 is 0.9656007289886475\n\n\nEpoch 36 Val loss: 0.2797752022743225\nAccuracy at Epoch 36 is 0.9320000410079956\n\nEpoch 37 Loss: 0.08502538502216339\nAccuracy at Epoch 37 is 0.9652493000030518\n\n\nEpoch 37 Val loss: 0.3403964340686798\nAccuracy at Epoch 37 is 0.9300000667572021\n\nEpoch 38 Loss: 0.0847526267170906\nAccuracy at Epoch 38 is 0.9649654030799866\n\n\nEpoch 38 Val loss: 0.3668551445007324\nAccuracy at Epoch 38 is 0.9190000295639038\n\nEpoch 39 Loss: 0.08641083538532257\nAccuracy at Epoch 39 is 0.9645058512687683\n\n\nEpoch 39 Val loss: 0.31529372930526733\nAccuracy at Epoch 39 is 0.9350000619888306\n\nEpoch 40 Loss: 0.08217049390077591\nAccuracy at Epoch 40 is 0.9664657711982727\n\n\nEpoch 40 Val loss: 0.2859049439430237\nAccuracy at Epoch 40 is 0.937000036239624\n\nEpoch 41 Loss: 0.08234212547540665\nAccuracy at Epoch 41 is 0.965681791305542\n\n\nEpoch 41 Val loss: 0.32038015127182007\nAccuracy at Epoch 41 is 0.9350000619888306\n\nEpoch 42 Loss: 0.08819189667701721\nAccuracy at Epoch 42 is 0.9638705849647522\n\n\nEpoch 42 Val loss: 0.2381812483072281\nAccuracy at Epoch 42 is 0.9500000476837158\n\nEpoch 43 Loss: 0.07625658065080643\nAccuracy at Epoch 43 is 0.9685337543487549\n\n\nEpoch 43 Val loss: 0.3046272099018097\nAccuracy at Epoch 43 is 0.9320000410079956\n\nEpoch 44 Loss: 0.07519051432609558\nAccuracy at Epoch 44 is 0.9680877327919006\n\n\nEpoch 44 Val loss: 0.2809126675128937\nAccuracy at Epoch 44 is 0.9510000348091125\n\nEpoch 45 Loss: 0.07825420796871185\nAccuracy at Epoch 45 is 0.9672091603279114\n\n\nEpoch 45 Val loss: 0.2706572711467743\nAccuracy at Epoch 45 is 0.9460000395774841\n\nEpoch 46 Loss: 0.08161772787570953\nAccuracy at Epoch 46 is 0.9664117097854614\n\n\nEpoch 46 Val loss: 0.2671080529689789\nAccuracy at Epoch 46 is 0.9430000185966492\n\nEpoch 47 Loss: 0.0769585520029068\nAccuracy at Epoch 47 is 0.9680066108703613\n\n\nEpoch 47 Val loss: 0.25138771533966064\nAccuracy at Epoch 47 is 0.9500000476837158\n\nEpoch 48 Loss: 0.0696297362446785\nAccuracy at Epoch 48 is 0.9702097773551941\n\n\nEpoch 48 Val loss: 0.2513595223426819\nAccuracy at Epoch 48 is 0.9540000557899475\n\nEpoch 49 Loss: 0.06728925555944443\nAccuracy at Epoch 49 is 0.9713181257247925\n\n\nEpoch 49 Val loss: 0.2475624829530716\nAccuracy at Epoch 49 is 0.9520000219345093\n\nEpoch 50 Loss: 0.07467743009328842\nAccuracy at Epoch 50 is 0.9684661626815796\n\n\nEpoch 50 Val loss: 0.24906744062900543\nAccuracy at Epoch 50 is 0.9440000653266907\n\nEpoch 51 Loss: 0.0737391784787178\nAccuracy at Epoch 51 is 0.9686148762702942\n\n\nEpoch 51 Val loss: 0.24984246492385864\nAccuracy at Epoch 51 is 0.956000030040741\n\nEpoch 52 Loss: 0.06802007555961609\nAccuracy at Epoch 52 is 0.9700611233711243\n\n\nEpoch 52 Val loss: 0.25824233889579773\nAccuracy at Epoch 52 is 0.9480000734329224\n\nEpoch 53 Loss: 0.0757637545466423\nAccuracy at Epoch 53 is 0.9679255485534668\n\n\nEpoch 53 Val loss: 0.27393192052841187\nAccuracy at Epoch 53 is 0.9460000395774841\n\nEpoch 54 Loss: 0.07147897779941559\nAccuracy at Epoch 54 is 0.9697232246398926\n\n\nEpoch 54 Val loss: 0.32056987285614014\nAccuracy at Epoch 54 is 0.9440000653266907\n\nEpoch 55 Loss: 0.07131262123584747\nAccuracy at Epoch 55 is 0.9689933061599731\n\n\nEpoch 55 Val loss: 0.2532397210597992\nAccuracy at Epoch 55 is 0.9470000267028809\n\nEpoch 56 Loss: 0.0654049664735794\nAccuracy at Epoch 56 is 0.9719128608703613\n\n\nEpoch 56 Val loss: 0.2998792231082916\nAccuracy at Epoch 56 is 0.9490000605583191\n\nEpoch 57 Loss: 0.0615818090736866\nAccuracy at Epoch 57 is 0.9729806780815125\n\n\nEpoch 57 Val loss: 0.28164926171302795\nAccuracy at Epoch 57 is 0.9570000171661377\n\nEpoch 58 Loss: 0.06754991412162781\nAccuracy at Epoch 58 is 0.9707639813423157\n\n\nEpoch 58 Val loss: 0.2727687358856201\nAccuracy at Epoch 58 is 0.9510000348091125\n\n","output_type":"stream"}]},{"cell_type":"code","source":"output = model(x_batch, mask, train_positional_encoding)\nprint(F.softmax(output[10], dim=-1))\ntorch.argmax(F.softmax(output[10], dim=-1)), y_batch[10]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"calculate_accuracy(output, y_batch)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nested_list = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\nflattened_list = sum(nested_list, [])\nprint(flattened_list)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}