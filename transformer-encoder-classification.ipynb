{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3176,"sourceType":"datasetVersion","datasetId":1835},{"sourceId":2510329,"sourceType":"datasetVersion","datasetId":1520310}],"dockerImageVersionId":30648,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch\nimport string\nimport re\nfrom torchtext.data.utils import get_tokenizer\nfrom torch.nn.utils.rnn import pad_sequence\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.nn import functional as F\nfrom sklearn.preprocessing import LabelEncoder\nfrom torchtext.vocab import build_vocab_from_iterator","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-01T17:27:51.565893Z","iopub.execute_input":"2024-03-01T17:27:51.566275Z","iopub.status.idle":"2024-03-01T17:27:57.109355Z","shell.execute_reply.started":"2024-03-01T17:27:51.566241Z","shell.execute_reply":"2024-03-01T17:27:57.108508Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"execution":{"iopub.status.busy":"2024-03-01T17:27:57.110961Z","iopub.execute_input":"2024-03-01T17:27:57.111599Z","iopub.status.idle":"2024-03-01T17:27:57.118566Z","shell.execute_reply.started":"2024-03-01T17:27:57.111567Z","shell.execute_reply":"2024-03-01T17:27:57.117740Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"device(type='cpu')"},"metadata":{}}]},{"cell_type":"code","source":"training_df = pd.read_csv('/kaggle/input/twitter-entity-sentiment-analysis/twitter_training.csv', header=None)\nvalidation_df = pd.read_csv('/kaggle/input/twitter-entity-sentiment-analysis/twitter_validation.csv', header=None)\ntraining_df.shape, validation_df.shape","metadata":{"execution":{"iopub.status.busy":"2024-03-01T17:27:57.119620Z","iopub.execute_input":"2024-03-01T17:27:57.120498Z","iopub.status.idle":"2024-03-01T17:27:57.417944Z","shell.execute_reply.started":"2024-03-01T17:27:57.120466Z","shell.execute_reply":"2024-03-01T17:27:57.417058Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"((74682, 4), (1000, 4))"},"metadata":{}}]},{"cell_type":"code","source":"print(f'Shape before dropping nulls {training_df.shape}')\ntraining_df = training_df.dropna()\nvalidation_df = validation_df.dropna()\nprint(f'Shape after dropping nulls {training_df.shape}')","metadata":{"execution":{"iopub.status.busy":"2024-03-01T17:27:57.421216Z","iopub.execute_input":"2024-03-01T17:27:57.421496Z","iopub.status.idle":"2024-03-01T17:27:57.449640Z","shell.execute_reply.started":"2024-03-01T17:27:57.421474Z","shell.execute_reply":"2024-03-01T17:27:57.449062Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Shape before dropping nulls (74682, 4)\nShape after dropping nulls (73996, 4)\n","output_type":"stream"}]},{"cell_type":"code","source":"validation_df.loc[:, 3] = validation_df.loc[:, 3].str.replace(re.escape(string.punctuation), ' ', regex=True)\nvalidation_df.loc[:, 3] = validation_df.loc[:, 3].str.replace(',', ' ', regex=True)\n\nvalidation_df.loc[:, 3] = validation_df.loc[:, 3].str.replace(re.escape(string.punctuation), ' ', regex=True)\nvalidation_df.loc[:, 3] = validation_df.loc[:, 3].str.replace(',', ' ', regex=True)","metadata":{"execution":{"iopub.status.busy":"2024-03-01T17:27:57.452141Z","iopub.execute_input":"2024-03-01T17:27:57.453230Z","iopub.status.idle":"2024-03-01T17:27:57.467718Z","shell.execute_reply.started":"2024-03-01T17:27:57.453204Z","shell.execute_reply":"2024-03-01T17:27:57.466891Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"tokenizer = get_tokenizer('basic_english')\n\ndef yield_tokens(data):\n    for text in data:\n        yield tokenizer(text)","metadata":{"execution":{"iopub.status.busy":"2024-03-01T17:27:57.468584Z","iopub.execute_input":"2024-03-01T17:27:57.468866Z","iopub.status.idle":"2024-03-01T17:27:57.473259Z","shell.execute_reply.started":"2024-03-01T17:27:57.468840Z","shell.execute_reply":"2024-03-01T17:27:57.472246Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"training_texts = training_df[3].tolist()\nval_texts = validation_df[3].tolist()\n\nvocab = build_vocab_from_iterator(yield_tokens(training_texts+val_texts), specials=['<unk>'])\nvocab.set_default_index(vocab['<unk>'])\n\ntext_pipeline = lambda x: vocab(tokenizer(x))\n(text_pipeline('im happy'))\n\n","metadata":{"execution":{"iopub.status.busy":"2024-03-01T17:27:57.474407Z","iopub.execute_input":"2024-03-01T17:27:57.474774Z","iopub.status.idle":"2024-03-01T17:27:58.730674Z","shell.execute_reply.started":"2024-03-01T17:27:57.474748Z","shell.execute_reply":"2024-03-01T17:27:58.730068Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"[313, 189]"},"metadata":{}}]},{"cell_type":"code","source":"int_training_texts = list(map(text_pipeline, training_texts))\nint_val_texts = list(map(text_pipeline, val_texts))\n\nprint(list(map(len, [int_training_texts, int_val_texts])))","metadata":{"execution":{"iopub.status.busy":"2024-03-01T17:27:58.731483Z","iopub.execute_input":"2024-03-01T17:27:58.731820Z","iopub.status.idle":"2024-03-01T17:28:00.100438Z","shell.execute_reply.started":"2024-03-01T17:27:58.731800Z","shell.execute_reply":"2024-03-01T17:28:00.099396Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"[73996, 1000]\n","output_type":"stream"}]},{"cell_type":"code","source":"le = LabelEncoder()\nle.fit(training_df[2])\n\ntraining_df['Labels']  = le.transform(training_df[2])\ntraining_output_y = training_df['Labels'].tolist()\n\nvalidation_df['Labels']  = le.transform(validation_df[2])\nvalidation_output_y = validation_df['Labels'].tolist()","metadata":{"execution":{"iopub.status.busy":"2024-03-01T17:28:00.103100Z","iopub.execute_input":"2024-03-01T17:28:00.103351Z","iopub.status.idle":"2024-03-01T17:28:00.127407Z","shell.execute_reply.started":"2024-03-01T17:28:00.103330Z","shell.execute_reply":"2024-03-01T17:28:00.126446Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def get_input_output(training_df, validation_df):\n    training_texts = training_df[3].tolist()\n    val_texts = validation_df[3].tolist()\n\n    tokenizer = get_tokenizer('basic_english')\n\n    training_tokenized = [tokenizer(text) for text in training_texts]\n    validation_tokenized = [tokenizer(text) for text in val_texts]\n                       \n    training_flattened_list = [token for tokens in training_tokenized for token in tokens]\n    validation_flattened_list = [token for tokens in validation_tokenized for token in tokens]\n\n    vocab = sorted(list(set(training_flattened_list)) + list(set(validation_flattened_list)))\n    word_to_id = {word:i+1 for i, word in enumerate(vocab)}\n    id_to_word = {i+1:word for i, word in enumerate(vocab)}\n\n    le = LabelEncoder()\n    le.fit(training_df[2])\n    \n    training_df['Labels']  = le.transform(training_df[2])\n    training_output_y = training_df['Labels'].tolist()\n    \n    validation_df['Labels']  = le.transform(validation_df[2])\n    validation_output_y = validation_df['Labels'].tolist()\n    \n    print(list(map(len, [training_tokenized, validation_tokenized, training_output_y, validation_output_y])))\n    \n    return training_tokenized, validation_tokenized, training_output_y, validation_output_y, word_to_id\n                       \ntrain_tokenized_texts, val_tokenized_texts, train_output_y, val_output_y, word_to_id = get_input_output(training_df, validation_df)","metadata":{"execution":{"iopub.status.busy":"2024-03-01T17:28:00.130250Z","iopub.execute_input":"2024-03-01T17:28:00.130523Z","iopub.status.idle":"2024-03-01T17:28:01.281641Z","shell.execute_reply.started":"2024-03-01T17:28:00.130500Z","shell.execute_reply":"2024-03-01T17:28:01.280809Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"[73996, 1000, 73996, 1000]\n","output_type":"stream"}]},{"cell_type":"code","source":"# # Read glove embeddings\n# glove_path = '/kaggle/input/glove-global-vectors-for-word-representation/glove.6B.100d.txt'\n\n# with open(glove_path, 'r') as file:\n#      lines = file.readlines()\n\n# print(len(lines))","metadata":{"execution":{"iopub.status.busy":"2024-03-01T17:28:01.282640Z","iopub.execute_input":"2024-03-01T17:28:01.282891Z","iopub.status.idle":"2024-03-01T17:28:01.286540Z","shell.execute_reply.started":"2024-03-01T17:28:01.282871Z","shell.execute_reply":"2024-03-01T17:28:01.285752Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# word_to_vec = dict()\n# for line in lines:\n#     word_and_vec = line.split(' ', maxsplit=1)\n#     word, vec = word_and_vec[0], word_and_vec[1]\n#     vec_array = np.fromstring(vec, sep=' ').astype('float32')\n#     word_to_vec[word] = vec_array\n","metadata":{"execution":{"iopub.status.busy":"2024-03-01T17:28:01.287765Z","iopub.execute_input":"2024-03-01T17:28:01.288389Z","iopub.status.idle":"2024-03-01T17:28:01.296135Z","shell.execute_reply.started":"2024-03-01T17:28:01.288366Z","shell.execute_reply":"2024-03-01T17:28:01.295285Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def padded_and_convert(tokens, output):\n#     encode_text = lambda x: [word_to_id[_] for _ in x]\n\n#     encoded_inputs = list(map(encode_text, tokens))\n    padded = pad_sequence(list(map(torch.tensor, tokens)), batch_first=True)\n    output_y = torch.tensor(output, dtype=torch.float32).unsqueeze(-1)\n    output_y = output_y.type(torch.LongTensor)\n    print(padded.shape, output_y.shape)\n    \n    return padded, output_y\n\ntrain_padded, train_y = padded_and_convert(int_training_texts, training_output_y)\nval_padded, val_y = padded_and_convert(int_val_texts, validation_output_y )\n\nmax_sequence_length = max(max(len(seq) for seq in train_padded), max(len(seq) for seq in val_padded))\nprint(max_sequence_length)\n\ntrain_padded = pad_sequence([torch.cat([seq, torch.zeros(max_sequence_length - len(seq))]) for seq in train_padded])\nval_padded = pad_sequence([torch.cat([seq, torch.zeros(max_sequence_length - len(seq))]) for seq in val_padded])\nprint(train_padded.shape, val_padded.shape)","metadata":{"execution":{"iopub.status.busy":"2024-03-01T17:28:01.297591Z","iopub.execute_input":"2024-03-01T17:28:01.298054Z","iopub.status.idle":"2024-03-01T17:28:04.183589Z","shell.execute_reply.started":"2024-03-01T17:28:01.298025Z","shell.execute_reply":"2024-03-01T17:28:04.182464Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"torch.Size([73996, 311]) torch.Size([73996, 1])\ntorch.Size([1000, 73]) torch.Size([1000, 1])\n311\ntorch.Size([311, 73996]) torch.Size([311, 1000])\n","output_type":"stream"}]},{"cell_type":"code","source":"def get_masks(padded):\n    B, T = padded.shape\n    mask = torch.eq(padded, 0).to(torch.float32)\n    mask = mask * -1e9\n    masked_reshape = mask.reshape(B, 1, T)\n    return masked_reshape\n\ntrain_mask = get_masks(train_padded)\nval_mask = get_masks(val_padded)","metadata":{"execution":{"iopub.status.busy":"2024-03-01T17:28:04.184771Z","iopub.execute_input":"2024-03-01T17:28:04.185064Z","iopub.status.idle":"2024-03-01T17:28:04.250000Z","shell.execute_reply.started":"2024-03-01T17:28:04.185042Z","shell.execute_reply":"2024-03-01T17:28:04.249205Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def get_angle(timesteps, dim):\n    k = np.arange(dim)[np.newaxis, :]\n    i = k // 2\n\n    positions = np.arange(timesteps)[:, np.newaxis]\n    angles = positions / (10000 ** (2*i/dim))\n\n    return angles\n\ndef get_positional_embeddings(angles):\n    angles[:, 0::2] = np.sin(angles[:, 0::2])\n    angles[:, 1::2] = np.cos(angles[:, 1::2])\n\n    return torch.tensor(angles, dtype=torch.float32)\nn_embed = 64\ntimesteps = train_padded.shape[-1]\nprint(timesteps)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-01T17:28:04.250964Z","iopub.execute_input":"2024-03-01T17:28:04.252434Z","iopub.status.idle":"2024-03-01T17:28:04.259659Z","shell.execute_reply.started":"2024-03-01T17:28:04.252406Z","shell.execute_reply":"2024-03-01T17:28:04.258906Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"73996\n","output_type":"stream"}]},{"cell_type":"code","source":"class Embedding(nn.Module):\n    def __init__(self, n_vocab, n_embed):\n        super().__init__()\n        self.embedding_layer = nn.Embedding(n_vocab, n_embed)\n        \n    def forward(self, x):\n        return self.embedding_layer(x)","metadata":{"execution":{"iopub.status.busy":"2024-03-01T17:28:04.260601Z","iopub.execute_input":"2024-03-01T17:28:04.260795Z","iopub.status.idle":"2024-03-01T17:28:04.269203Z","shell.execute_reply.started":"2024-03-01T17:28:04.260777Z","shell.execute_reply":"2024-03-01T17:28:04.268554Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"class Head(nn.Module):\n    def __init__(self, head_size=16):\n        super().__init__()\n        self.query = nn.Linear(n_embed, head_size)\n        self.key = nn.Linear(n_embed, head_size)\n        self.value = nn.Linear(n_embed, head_size)\n        \n    def forward(self, x, mask):\n        B, T, C = x.shape\n        \n        query = self.query(x)\n        key = self.key(x)\n        value = self.value(x)\n        \n        wei = query @ key.transpose(-2, -1)\n        \n        if mask is not None:\n            wei = wei + mask\n        \n        wei = F.softmax(wei, dim=-1)\n        out = wei @ value # (B, T, head_size)\n        \n        return out","metadata":{"execution":{"iopub.status.busy":"2024-03-01T17:28:04.270027Z","iopub.execute_input":"2024-03-01T17:28:04.270672Z","iopub.status.idle":"2024-03-01T17:28:04.281258Z","shell.execute_reply.started":"2024-03-01T17:28:04.270650Z","shell.execute_reply":"2024-03-01T17:28:04.280728Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"class Encoder(nn.Module):\n    def __init__(self, n_vocab, n_embed, timesteps, head_size, output):\n        super().__init__() # What happens if I pass the class name in super?\n        self.embedding = Embedding(n_vocab, n_embed)\n        self.sa = Head(head_size)\n        self.inter1_layer = nn.Linear(head_size, timesteps)\n        self.output = nn.Linear(timesteps**2, output)\n        \n    def forward(self, x, mask, positional_encoding):\n        B, T = x.shape # validation shape --> (1000, 73)\n#         print(self.embedding(x).shape, positional_encoding.shape)\n        embedding = self.embedding(x) + positional_encoding # (B, timesteps, n_embed) # validation: (1000, 73, 64)\n        sa_out = self.sa(embedding, mask) # (B, timesteps, head_size) # validation: (1000, 73, 16)\n        inter1 = self.inter1_layer(sa_out) # (B, timesteps, head_size) @ (head_size, timesteps) --> (B, timesteps, timesteps)\n        output = self.output(inter1.view(B, -1))\n#         output = F.softmax(output, dim=-1)\n        \n        return output","metadata":{"execution":{"iopub.status.busy":"2024-03-01T17:28:04.281994Z","iopub.execute_input":"2024-03-01T17:28:04.282974Z","iopub.status.idle":"2024-03-01T17:28:04.292654Z","shell.execute_reply.started":"2024-03-01T17:28:04.282869Z","shell.execute_reply":"2024-03-01T17:28:04.291746Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# split = 0.8\n# train_size = int(split * padded.shape[0])\n\n# x_train, x_val, y_train, y_val = padded[:train_size], padded[train_size:], output_y[:train_size], output_y[train_size:]\n# x_train, x_val, y_train, y_val = x_train.to(device), x_val.to(device), y_train.to(device), y_val.to(device)\n# mask_train, mask_val = masked_reshape[:train_size], masked_reshape[train_size:]\n# mask_train, mask_val = mask_train.to(device), mask_val.to(device)\n# list(map(lambda x: x.shape, [x_train, x_val, y_train, y_val, mask_train, mask_val]))","metadata":{"execution":{"iopub.status.busy":"2024-03-01T17:28:04.293757Z","iopub.execute_input":"2024-03-01T17:28:04.293999Z","iopub.status.idle":"2024-03-01T17:28:04.300398Z","shell.execute_reply.started":"2024-03-01T17:28:04.293978Z","shell.execute_reply":"2024-03-01T17:28:04.299542Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"def train_epoch(x_batch, mask, y_batch, positional_encoding):\n    optimizer.zero_grad()\n    output = model(x_batch, mask, positional_encoding)\n    \n    loss = loss_function(output, y_batch.view(-1))\n\n    loss.backward()\n    optimizer.step()\n    \n    return loss","metadata":{"execution":{"iopub.status.busy":"2024-03-01T17:28:04.301616Z","iopub.execute_input":"2024-03-01T17:28:04.301943Z","iopub.status.idle":"2024-03-01T17:28:04.314006Z","shell.execute_reply.started":"2024-03-01T17:28:04.301915Z","shell.execute_reply":"2024-03-01T17:28:04.313301Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"train_padded, train_y = train_padded.to(device), train_y.to(device)\nval_padded, val_y = val_padded.to(device), val_y.to(device) \ntrain_mask, val_mask = train_mask.to(device), val_mask.to(device)\ntrain_positional_encoding = get_positional_embeddings(get_angle(timesteps, n_embed)).to(device)\nval_positional_encoding = get_positional_embeddings(get_angle(val_padded.shape[-1], n_embed)).to(device)\n\nn_embed = 64\ntimesteps = train_padded.shape[-1]\nmodel = Encoder(vocab.get_itos().__len__(), n_embed, timesteps, head_size=16, output=4)\nbatch_size = 64\nbatch_per_epoch = train_padded.shape[0] // batch_size\n\n# loss_function = nn.BCELoss()\nloss_function = nn.CrossEntropyLoss()\nlearning_rate = 0.001 \noptimizer = optim.Adam(model.parameters(), lr=learning_rate)\n\n# Set the device (CPU or GPU)\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-03-01T17:28:04.315031Z","iopub.execute_input":"2024-03-01T17:28:04.315420Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# model = torch.nn.DataParallel(model, device_ids = [0,1]).to(device)\n# output_y = output_y.type(torch.LongTensor)\n# inputs, targets, masked_reshape = padded.to(device), output_y.to(device), masked_reshape.to(device)\n\nfor epoch in range(10):\n    train_loss, val_loss = 0, 0\n    for i in range(batch_per_epoch):\n        start = i * batch_size\n        x_batch, y_batch, mask = train_padded[start:start+batch_size], train_y[start:start+batch_size], train_mask[start:start+batch_size]\n\n        model.train(True)\n        loss = train_epoch(x_batch, mask, y_batch, train_positional_encoding)\n        train_loss += loss\n        \n    print(f'Epoch {epoch} Loss: {train_loss / (i+1)}')   \n    model.eval()\n    with torch.no_grad():\n        output_val = model(val_padded, val_mask, val_positional_encoding)\n        loss_val = loss_function(output_val, val_y.view(-1))\n        print(f'Epoch {epoch} Val loss: {loss_val}')\n        \n    print()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nested_list = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\nflattened_list = sum(nested_list, [])\nprint(flattened_list)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}