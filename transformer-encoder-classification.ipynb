{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3176,"sourceType":"datasetVersion","datasetId":1835},{"sourceId":2510329,"sourceType":"datasetVersion","datasetId":1520310}],"dockerImageVersionId":30648,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch\nimport string\nimport re\nfrom torchtext.data.utils import get_tokenizer\nfrom torch.nn.utils.rnn import pad_sequence\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.nn import functional as F\nfrom sklearn.preprocessing import LabelEncoder\nfrom torchtext.vocab import build_vocab_from_iterator\nimport torchtext.vocab as vocab","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-02-29T09:09:02.373877Z","iopub.execute_input":"2024-02-29T09:09:02.374325Z","iopub.status.idle":"2024-02-29T09:09:02.380457Z","shell.execute_reply.started":"2024-02-29T09:09:02.374298Z","shell.execute_reply":"2024-02-29T09:09:02.379370Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"training_df = pd.read_csv('/kaggle/input/twitter-entity-sentiment-analysis/twitter_training.csv', header=None)\ntraining_df.shape","metadata":{"execution":{"iopub.status.busy":"2024-02-29T09:09:02.381749Z","iopub.execute_input":"2024-02-29T09:09:02.382027Z","iopub.status.idle":"2024-02-29T09:09:02.602605Z","shell.execute_reply.started":"2024-02-29T09:09:02.382004Z","shell.execute_reply":"2024-02-29T09:09:02.601752Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"(74682, 4)"},"metadata":{}}]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"training_df.sample(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'Shape before dropping nulls {training_df.shape}')\ntraining_df = training_df.dropna()\nprint(f'Shape after dropping nulls {training_df.shape}')","metadata":{"execution":{"iopub.status.busy":"2024-02-29T09:09:06.548340Z","iopub.execute_input":"2024-02-29T09:09:06.549166Z","iopub.status.idle":"2024-02-29T09:09:06.586243Z","shell.execute_reply.started":"2024-02-29T09:09:06.549133Z","shell.execute_reply":"2024-02-29T09:09:06.585278Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Shape before dropping nulls (74682, 4)\nShape after dropping nulls (73996, 4)\n","output_type":"stream"}]},{"cell_type":"code","source":"training_df.loc[:, 3] = training_df.loc[:, 3].str.replace(re.escape(string.punctuation), ' ', regex=True)\ntraining_df.loc[:, 3] = training_df.loc[:, 3].str.replace(',', ' ', regex=True)","metadata":{"execution":{"iopub.status.busy":"2024-02-29T09:09:10.309583Z","iopub.execute_input":"2024-02-29T09:09:10.309957Z","iopub.status.idle":"2024-02-29T09:09:10.455622Z","shell.execute_reply.started":"2024-02-29T09:09:10.309930Z","shell.execute_reply":"2024-02-29T09:09:10.454632Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"input_texts = training_df[3].tolist()\nprint(len(input_texts))\n\ntokenizer = get_tokenizer('basic_english')\n\ntokenized_texts = [tokenizer(text) for text in input_texts]\n# tokenized_texts = tokenized_texts\n\n\n\n# flattened_list = sum(tokenized_texts, [])\nflattened_list = [token for tokens in tokenized_texts for token in tokens]\n\nvocab = sorted(list(set(flattened_list)))\nword_to_id = {word:i+1 for i, word in enumerate(vocab)}\nid_to_word = {i+1:word for i, word in enumerate(vocab)}\n\nle = LabelEncoder()\ntraining_df['Labels']  = le.fit_transform(training_df[2])\noutput_y = training_df['Labels'].tolist()","metadata":{"execution":{"iopub.status.busy":"2024-02-29T09:09:14.971118Z","iopub.execute_input":"2024-02-29T09:09:14.971510Z","iopub.status.idle":"2024-02-29T09:09:16.907053Z","shell.execute_reply.started":"2024-02-29T09:09:14.971481Z","shell.execute_reply":"2024-02-29T09:09:16.906221Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"73996\n","output_type":"stream"}]},{"cell_type":"code","source":"# Read glove embeddings\nglove_path = '/kaggle/input/glove-global-vectors-for-word-representation/glove.6B.100d.txt'\n\nwith open(glove_path, 'r') as file:\n     lines = file.readlines()\n\nprint(len(lines))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"word_to_vec = dict()\nfor line in lines:\n    word_and_vec = line.split(' ', maxsplit=1)\n    word, vec = word_and_vec[0], word_and_vec[1]\n    vec_array = np.fromstring(vec, sep=' ').astype('float32')\n    word_to_vec[word] = vec_array\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_x = ['I loved the movie', 'The product exceeded my expectations', 'The service was terrible', 'The performance of the device is disappointing']\noutput_y = [1, 1, 0, 0]\n\ninput_x = list(map(str.lower, input_x))\ntokenized_inputs = [tokenizer(text) for text in input_x]\nflattened_list = sum(tokenized_inputs, [])\nprint(flattened_list)\nvocab = sorted(list(set(flattened_list)))\nword_to_id = {word:i+1 for i, word in enumerate(vocab)}\nid_to_word = {i+1:word for i, word in enumerate(vocab)}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encode_text = lambda x: [word_to_id[_] for _ in x]\n\nencoded_inputs = list(map(encode_text, tokenized_texts))\npadded = pad_sequence(list(map(torch.tensor, encoded_inputs)), batch_first=True)\noutput_y = torch.tensor(output_y, dtype=torch.float32).unsqueeze(-1)\noutput_y = output_y.type(torch.LongTensor)\npadded.shape, output_y.shape","metadata":{"execution":{"iopub.status.busy":"2024-02-29T09:11:33.199308Z","iopub.execute_input":"2024-02-29T09:11:33.199689Z","iopub.status.idle":"2024-02-29T09:11:35.222793Z","shell.execute_reply.started":"2024-02-29T09:11:33.199660Z","shell.execute_reply":"2024-02-29T09:11:35.221798Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_208/55451862.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  output_y = torch.tensor(output_y, dtype=torch.float32).unsqueeze(-1)\n","output_type":"stream"},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"(torch.Size([73996, 311]), torch.Size([73996, 1, 1]))"},"metadata":{}}]},{"cell_type":"code","source":"B, T = padded.shape\nmask = torch.eq(padded, 0).to(torch.float32)\nmask = mask * -1e9\nmasked_reshape = mask.reshape(B, 1, T)","metadata":{"execution":{"iopub.status.busy":"2024-02-29T09:09:27.078553Z","iopub.execute_input":"2024-02-29T09:09:27.079059Z","iopub.status.idle":"2024-02-29T09:09:27.175832Z","shell.execute_reply.started":"2024-02-29T09:09:27.079024Z","shell.execute_reply":"2024-02-29T09:09:27.174819Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"class Embedding(nn.Module):\n    def __init__(self, n_vocab, n_embed):\n        super().__init__()\n        self.embedding_layer = nn.Embedding(n_vocab, n_embed)\n        \n    def forward(self, x):\n        return self.embedding_layer(x)","metadata":{"execution":{"iopub.status.busy":"2024-02-29T09:09:30.809334Z","iopub.execute_input":"2024-02-29T09:09:30.810014Z","iopub.status.idle":"2024-02-29T09:09:30.815512Z","shell.execute_reply.started":"2024-02-29T09:09:30.809979Z","shell.execute_reply":"2024-02-29T09:09:30.814572Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"class Head(nn.Module):\n    def __init__(self, head_size=16):\n        super().__init__()\n        self.query = nn.Linear(n_embed, head_size)\n        self.key = nn.Linear(n_embed, head_size)\n        self.value = nn.Linear(n_embed, head_size)\n        \n    def forward(self, x, mask):\n        B, T, C = x.shape\n        \n        query = self.query(x)\n        key = self.key(x)\n        value = self.value(x)\n        \n        wei = query @ key.transpose(-2, -1)\n        \n        if mask is not None:\n            wei = wei + mask\n        \n        wei = F.softmax(wei, dim=-1)\n        out = wei @ value # (B, T, head_size)\n        \n        return out","metadata":{"execution":{"iopub.status.busy":"2024-02-29T09:09:31.750054Z","iopub.execute_input":"2024-02-29T09:09:31.750381Z","iopub.status.idle":"2024-02-29T09:09:31.758145Z","shell.execute_reply.started":"2024-02-29T09:09:31.750357Z","shell.execute_reply":"2024-02-29T09:09:31.757044Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"execution":{"iopub.status.busy":"2024-02-29T09:09:34.099105Z","iopub.execute_input":"2024-02-29T09:09:34.099472Z","iopub.status.idle":"2024-02-29T09:09:34.154757Z","shell.execute_reply.started":"2024-02-29T09:09:34.099444Z","shell.execute_reply":"2024-02-29T09:09:34.153802Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"cell_type":"code","source":"class Encoder(nn.Module):\n    def __init__(self, n_vocab, n_embed, timesteps, head_size, output):\n        super().__init__() # What happens if I pass the class name in super?\n        self.embedding = Embedding(n_vocab, n_embed)\n        self.positional_encodings = self.get_positional_embeddings(self.get_angle(timesteps, n_embed)).to(device)\n        self.sa = Head(head_size)\n        self.inter1_layer = nn.Linear(head_size, timesteps)\n        self.output = nn.Linear(timesteps**2, output)\n        \n    def forward(self, x, mask):\n        B, T = x.shape\n        embedding = self.embedding(x) + self.positional_encodings # (B, timesteps, n_embed)\n        sa_out = self.sa(embedding, mask) # (B, timesteps, head_size)\n        inter1 = self.inter1_layer(sa_out) # (B, timesteps, head_size) @ (head_size, timesteps) --> (B, timesteps, timesteps)\n        output = self.output(inter1.view(B, -1))\n#         output = F.softmax(output, dim=-1)\n        \n        return output\n    \n    def get_angle(self, timesteps, dim):\n        k = np.arange(dim)[np.newaxis, :]\n        i = k // 2\n        \n        positions = np.arange(timesteps)[:, np.newaxis]\n        angles = positions / (10000 ** (2*i/dim))\n        \n        return angles\n    \n    def get_positional_embeddings(self, angles):\n        angles[:, 0::2] = np.sin(angles[:, 0::2])\n        angles[:, 1::2] = np.cos(angles[:, 1::2])\n        \n        return torch.tensor(angles, dtype=torch.float32)","metadata":{"execution":{"iopub.status.busy":"2024-02-29T09:09:40.113758Z","iopub.execute_input":"2024-02-29T09:09:40.114225Z","iopub.status.idle":"2024-02-29T09:09:40.129123Z","shell.execute_reply.started":"2024-02-29T09:09:40.114190Z","shell.execute_reply":"2024-02-29T09:09:40.127937Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"split = 0.8\ntrain_size = int(split * padded.shape[0])\n\nx_train, x_val, y_train, y_val = padded[:train_size], padded[train_size:], output_y[:train_size], output_y[train_size:]\nx_train, x_val, y_train, y_val = x_train.to(device), x_val.to(device), y_train.to(device), y_val.to(device)\nmask_train, mask_val = masked_reshape[:train_size], masked_reshape[train_size:]\nmask_train, mask_val = mask_train.to(device), mask_val.to(device)\nlist(map(lambda x: x.shape, [x_train, x_val, y_train, y_val, mask_train, mask_val]))","metadata":{"execution":{"iopub.status.busy":"2024-02-29T09:11:49.391894Z","iopub.execute_input":"2024-02-29T09:11:49.392791Z","iopub.status.idle":"2024-02-29T09:11:49.462086Z","shell.execute_reply.started":"2024-02-29T09:11:49.392759Z","shell.execute_reply":"2024-02-29T09:11:49.461091Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"[torch.Size([59196, 311]),\n torch.Size([14800, 311]),\n torch.Size([59196, 1, 1]),\n torch.Size([14800, 1, 1]),\n torch.Size([59196, 1, 311]),\n torch.Size([14800, 1, 311])]"},"metadata":{}}]},{"cell_type":"code","source":"padded.shape[0] // 2028","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_embed = 64\ntimesteps = padded.shape[-1]\nmodel = Encoder(len(vocab) + 1, n_embed, timesteps, head_size=16, output=4)\nbatch_size = 64\nbatch_per_epoch = x_train.shape[0] // batch_size\n\n# loss_function = nn.BCELoss()\nloss_function = nn.CrossEntropyLoss()\nlearning_rate = 0.001 \noptimizer = optim.Adam(model.parameters(), lr=learning_rate)\n\n# Set the device (CPU or GPU)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n# output_y = output_y.type(torch.LongTensor)\n# inputs, targets, masked_reshape = padded.to(device), output_y.to(device), masked_reshape.to(device)\n\nfor epoch in range(10):\n    train_loss, val_loss = 0, 0\n    for i in range(batch_per_epoch):\n        start = i * batch_size\n        x_batch, y_batch, mask = x_train[start:start+batch_size], y_train[start:start+batch_size], mask_train[start:start+batch_size]\n\n        model.train(True)\n\n        optimizer.zero_grad()\n        output = model(x_batch, mask)\n        loss = loss_function(output, y_batch.view(-1))\n        train_loss += loss\n        \n        loss.backward()\n        optimizer.step()\n        \n    print(f'Epoch {epoch} Loss {i}: {train_loss / (i+1)}')   \n    model.eval()\n    with torch.no_grad():\n        output_val = model(x_val, mask_val)\n        loss_val = loss_function(output_val, y_val.view(-1))\n        print(f'Epoch {epoch} Val loss: {loss_val}')","metadata":{"execution":{"iopub.status.busy":"2024-02-29T09:11:52.890420Z","iopub.execute_input":"2024-02-29T09:11:52.891150Z","iopub.status.idle":"2024-02-29T09:12:49.716802Z","shell.execute_reply.started":"2024-02-29T09:11:52.891119Z","shell.execute_reply":"2024-02-29T09:12:49.715735Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Epoch 0 Loss 923: 1.9859893321990967\nEpoch 0 Val loss: 1.5022014379501343\nEpoch 1 Loss 923: 1.3363515138626099\nEpoch 1 Val loss: 1.45757257938385\nEpoch 2 Loss 923: 1.1962958574295044\nEpoch 2 Val loss: 1.5224149227142334\nEpoch 3 Loss 923: 1.076869010925293\nEpoch 3 Val loss: 1.9083342552185059\nEpoch 4 Loss 923: 0.9610947966575623\nEpoch 4 Val loss: 2.1496798992156982\nEpoch 5 Loss 923: 0.8442988395690918\nEpoch 5 Val loss: 2.8225908279418945\nEpoch 6 Loss 923: 0.7202357649803162\nEpoch 6 Val loss: 2.80661940574646\nEpoch 7 Loss 923: 0.6065431237220764\nEpoch 7 Val loss: 2.5435023307800293\nEpoch 8 Loss 923: 0.5160390734672546\nEpoch 8 Val loss: 2.1813507080078125\nEpoch 9 Loss 923: 0.4337286949157715\nEpoch 9 Val loss: 2.438356637954712\n","output_type":"stream"}]},{"cell_type":"code","source":"print(start, start + batch_size)\nx_train[start : start + batch_size], x_train.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_per_epoch = x_train.shape[0] // batch_size\nprint(batch_per_epoch)\n\nfor i in range(batch_per_epoch+1):\n    start = i * batch_size\n    print(i, start, start+batch_size)\n    print(x_train[start : start+batch_size].shape)\n    print()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nested_list = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\nflattened_list = sum(nested_list, [])\nprint(flattened_list)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}