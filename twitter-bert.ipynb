{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from transformers import BertTokenizer, BertForSequenceClassification, AdamW\nimport numpy as np\nimport pandas as pd\nimport torch\nimport string\nimport re\nfrom torchtext.data.utils import get_tokenizer\nfrom torch.nn.utils.rnn import pad_sequence\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.nn import functional as F\nfrom sklearn.preprocessing import LabelEncoder\nfrom torchtext.vocab import build_vocab_from_iterator\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom tqdm import tqdm\nfrom sklearn.metrics import accuracy_score","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-05T16:56:47.069395Z","iopub.execute_input":"2024-03-05T16:56:47.070117Z","iopub.status.idle":"2024-03-05T16:56:47.165688Z","shell.execute_reply.started":"2024-03-05T16:56:47.070086Z","shell.execute_reply":"2024-03-05T16:56:47.164880Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"execution":{"iopub.status.busy":"2024-03-05T14:54:26.578192Z","iopub.execute_input":"2024-03-05T14:54:26.578776Z","iopub.status.idle":"2024-03-05T14:54:26.634445Z","shell.execute_reply.started":"2024-03-05T14:54:26.578749Z","shell.execute_reply":"2024-03-05T14:54:26.633299Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"cell_type":"code","source":"training_df = pd.read_csv('/kaggle/input/twitter-entity-sentiment-analysis/twitter_training.csv', header=None)\nvalidation_df = pd.read_csv('/kaggle/input/twitter-entity-sentiment-analysis/twitter_validation.csv', header=None)\nprint(training_df.shape, validation_df.shape)\n\nprint(f'Shape before dropping nulls {training_df.shape}')\ntraining_df = training_df.dropna()\nvalidation_df = validation_df.dropna()\nprint(f'Shape after dropping nulls {training_df.shape}')\n\n","metadata":{"execution":{"iopub.status.busy":"2024-03-05T14:54:26.635733Z","iopub.execute_input":"2024-03-05T14:54:26.636584Z","iopub.status.idle":"2024-03-05T14:54:27.021462Z","shell.execute_reply.started":"2024-03-05T14:54:26.636551Z","shell.execute_reply":"2024-03-05T14:54:27.020399Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"(74682, 4) (1000, 4)\nShape before dropping nulls (74682, 4)\nShape after dropping nulls (73996, 4)\n","output_type":"stream"}]},{"cell_type":"code","source":"import re\n\ndef clean_text(tweet):\n    # Remove URLs\n    tweet = re.sub(r'http\\S+', '', tweet)\n    \n    # Remove mentions and hashtags\n    tweet = re.sub(r'@[A-Za-z0-9_]+|#[A-Za-z0-9_]+', '', tweet)\n    \n    # Remove special characters, numbers, and punctuation\n    tweet = re.sub(r'[^A-Za-z\\s]', '', tweet)\n    \n    # Remove 'RT' (Retweet) indicator\n    tweet = re.sub(r'\\bRT\\b', '', tweet)\n    \n    return tweet.lower()","metadata":{"execution":{"iopub.status.busy":"2024-03-05T14:54:27.023648Z","iopub.execute_input":"2024-03-05T14:54:27.023951Z","iopub.status.idle":"2024-03-05T14:54:27.029415Z","shell.execute_reply.started":"2024-03-05T14:54:27.023926Z","shell.execute_reply":"2024-03-05T14:54:27.028474Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"training_df.loc[:, 3] = training_df[3].apply(clean_text)\nvalidation_df.loc[:, 3] = validation_df[3].apply(clean_text)","metadata":{"execution":{"iopub.status.busy":"2024-03-05T14:54:27.030332Z","iopub.execute_input":"2024-03-05T14:54:27.030606Z","iopub.status.idle":"2024-03-05T14:54:28.245892Z","shell.execute_reply.started":"2024-03-05T14:54:27.030584Z","shell.execute_reply":"2024-03-05T14:54:28.245100Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"le = LabelEncoder()\nle.fit(training_df[2])\n\ntraining_df['Labels']  = le.transform(training_df[2])\ntraining_output_y = training_df['Labels'].tolist()\n\nvalidation_df['Labels']  = le.transform(validation_df[2])\nvalidation_output_y = validation_df['Labels'].tolist()","metadata":{"execution":{"iopub.status.busy":"2024-03-05T14:54:28.247050Z","iopub.execute_input":"2024-03-05T14:54:28.247397Z","iopub.status.idle":"2024-03-05T14:54:28.275306Z","shell.execute_reply.started":"2024-03-05T14:54:28.247369Z","shell.execute_reply":"2024-03-05T14:54:28.274330Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\nmodel = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(le.classes_)) ","metadata":{"execution":{"iopub.status.busy":"2024-03-05T14:54:28.276232Z","iopub.execute_input":"2024-03-05T14:54:28.276580Z","iopub.status.idle":"2024-03-05T14:54:32.723234Z","shell.execute_reply.started":"2024-03-05T14:54:28.276553Z","shell.execute_reply":"2024-03-05T14:54:32.722510Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"053df910e9a549948384b1b3abccb940"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6bf3baed42d042c8808731ed29e458a6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"717752faafa3403f8b4ece5270e9d73d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"62dd1424297c46259d9300be9a651857"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"65b687c065454ae09427de0496fd90f9"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"train_encodings = tokenizer(training_df[3].tolist(), truncation=True, padding=True, max_length=512, return_tensors='pt')\ntest_encodings = tokenizer(validation_df[3].tolist(), truncation=True, padding=True, max_length=512, return_tensors='pt')","metadata":{"execution":{"iopub.status.busy":"2024-03-05T14:54:32.724288Z","iopub.execute_input":"2024-03-05T14:54:32.724581Z","iopub.status.idle":"2024-03-05T14:55:40.710226Z","shell.execute_reply.started":"2024-03-05T14:54:32.724556Z","shell.execute_reply":"2024-03-05T14:55:40.709279Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"training_df","metadata":{"execution":{"iopub.status.busy":"2024-03-05T14:55:40.711648Z","iopub.execute_input":"2024-03-05T14:55:40.711941Z","iopub.status.idle":"2024-03-05T14:55:40.729269Z","shell.execute_reply.started":"2024-03-05T14:55:40.711916Z","shell.execute_reply":"2024-03-05T14:55:40.728450Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"          0            1         2  \\\n0      2401  Borderlands  Positive   \n1      2401  Borderlands  Positive   \n2      2401  Borderlands  Positive   \n3      2401  Borderlands  Positive   \n4      2401  Borderlands  Positive   \n...     ...          ...       ...   \n74677  9200       Nvidia  Positive   \n74678  9200       Nvidia  Positive   \n74679  9200       Nvidia  Positive   \n74680  9200       Nvidia  Positive   \n74681  9200       Nvidia  Positive   \n\n                                                       3  Labels  \n0      im getting on borderlands and i will murder yo...       3  \n1      i am coming to the borders and i will kill you...       3  \n2      im getting on borderlands and i will kill you all       3  \n3      im coming on borderlands and i will murder you...       3  \n4      im getting on borderlands  and i will murder y...       3  \n...                                                  ...     ...  \n74677  just realized that the windows partition of my...       3  \n74678  just realized that my mac window partition is ...       3  \n74679  just realized the windows partition of my mac ...       3  \n74680  just realized between the windows partition of...       3  \n74681  just like the windows partition of my mac is l...       3  \n\n[73996 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>Labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2401</td>\n      <td>Borderlands</td>\n      <td>Positive</td>\n      <td>im getting on borderlands and i will murder yo...</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2401</td>\n      <td>Borderlands</td>\n      <td>Positive</td>\n      <td>i am coming to the borders and i will kill you...</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2401</td>\n      <td>Borderlands</td>\n      <td>Positive</td>\n      <td>im getting on borderlands and i will kill you all</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2401</td>\n      <td>Borderlands</td>\n      <td>Positive</td>\n      <td>im coming on borderlands and i will murder you...</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2401</td>\n      <td>Borderlands</td>\n      <td>Positive</td>\n      <td>im getting on borderlands  and i will murder y...</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>74677</th>\n      <td>9200</td>\n      <td>Nvidia</td>\n      <td>Positive</td>\n      <td>just realized that the windows partition of my...</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>74678</th>\n      <td>9200</td>\n      <td>Nvidia</td>\n      <td>Positive</td>\n      <td>just realized that my mac window partition is ...</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>74679</th>\n      <td>9200</td>\n      <td>Nvidia</td>\n      <td>Positive</td>\n      <td>just realized the windows partition of my mac ...</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>74680</th>\n      <td>9200</td>\n      <td>Nvidia</td>\n      <td>Positive</td>\n      <td>just realized between the windows partition of...</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>74681</th>\n      <td>9200</td>\n      <td>Nvidia</td>\n      <td>Positive</td>\n      <td>just like the windows partition of my mac is l...</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n<p>73996 rows × 5 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train_dataset = TensorDataset(train_encodings['input_ids'], train_encodings['attention_mask'], torch.tensor(training_df['Labels'].tolist()))\ntest_dataset = TensorDataset(test_encodings['input_ids'], test_encodings['attention_mask'], torch.tensor(validation_df['Labels'].tolist()))\n\n# Create DataLoader\ntrain_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\ntest_dataloader = DataLoader(test_dataset, batch_size=8, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-03-05T14:55:40.731592Z","iopub.execute_input":"2024-03-05T14:55:40.731854Z","iopub.status.idle":"2024-03-05T14:55:40.762051Z","shell.execute_reply.started":"2024-03-05T14:55:40.731831Z","shell.execute_reply":"2024-03-05T14:55:40.761316Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"optimizer = AdamW(model.parameters(), lr=1e-5)\nloss_fn = torch.nn.CrossEntropyLoss()","metadata":{"execution":{"iopub.status.busy":"2024-03-05T14:55:40.763351Z","iopub.execute_input":"2024-03-05T14:55:40.763815Z","iopub.status.idle":"2024-03-05T14:55:40.778498Z","shell.execute_reply.started":"2024-03-05T14:55:40.763783Z","shell.execute_reply":"2024-03-05T14:55:40.777473Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"model.to(device)\nepochs = 3\nfor epoch in range(epochs):\n    model.train()\n    total_loss = 0\n    for batch in tqdm(train_dataloader, desc=f'Epoch {epoch + 1}/{epochs}'):\n        input_ids, attention_mask, labels = batch\n        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n\n        optimizer.zero_grad()\n        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n        loss = outputs.loss\n        total_loss += loss.item()\n\n        loss.backward()\n        optimizer.step()\n\n    avg_train_loss = total_loss / len(train_dataloader)\n    print(f'Average Training Loss: {avg_train_loss}')\n\n# Evaluation\nmodel.eval()\npredictions = []\ntrue_labels = []\n\nfor batch in tqdm(test_dataloader, desc='Evaluating'):\n    input_ids, attention_mask, labels = batch\n    input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n\n    with torch.no_grad():\n        outputs = model(input_ids, attention_mask=attention_mask)\n    \n    logits = outputs.logits\n    _, predicted_labels = torch.max(logits, dim=1)\n\n    predictions.extend(predicted_labels.cpu().numpy())\n    true_labels.extend(labels.cpu().numpy())\n\n# Calculate accuracy\naccuracy = accuracy_score(true_labels, predictions)\nprint(f'Accuracy: {accuracy * 100:.2f}%')\n","metadata":{"execution":{"iopub.status.busy":"2024-03-05T14:57:26.866377Z","iopub.execute_input":"2024-03-05T14:57:26.867109Z","iopub.status.idle":"2024-03-05T16:51:07.921451Z","shell.execute_reply.started":"2024-03-05T14:57:26.867077Z","shell.execute_reply":"2024-03-05T16:51:07.920064Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"Epoch 1/3: 100%|██████████| 9250/9250 [37:50<00:00,  4.07it/s]\n","output_type":"stream"},{"name":"stdout","text":"Average Training Loss: 0.8235388864713746\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/3: 100%|██████████| 9250/9250 [37:51<00:00,  4.07it/s]\n","output_type":"stream"},{"name":"stdout","text":"Average Training Loss: 0.34332437679322586\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/3: 100%|██████████| 9250/9250 [37:54<00:00,  4.07it/s]\n","output_type":"stream"},{"name":"stdout","text":"Average Training Loss: 0.17270297830032713\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|██████████| 125/125 [00:04<00:00, 27.92it/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[13], line 40\u001b[0m\n\u001b[1;32m     37\u001b[0m     true_labels\u001b[38;5;241m.\u001b[39mextend(labels\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# Calculate accuracy\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m \u001b[43maccuracy_score\u001b[49m(true_labels, predictions)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m'\u001b[39m)\n","\u001b[0;31mNameError\u001b[0m: name 'accuracy_score' is not defined"],"ename":"NameError","evalue":"name 'accuracy_score' is not defined","output_type":"error"}]},{"cell_type":"code","source":"accuracy = accuracy_score(true_labels, predictions)\nprint(f'Accuracy: {accuracy * 100:.2f}%')\n","metadata":{"execution":{"iopub.status.busy":"2024-03-05T16:57:15.293103Z","iopub.execute_input":"2024-03-05T16:57:15.294096Z","iopub.status.idle":"2024-03-05T16:57:15.303096Z","shell.execute_reply.started":"2024-03-05T16:57:15.294050Z","shell.execute_reply":"2024-03-05T16:57:15.302069Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Accuracy: 97.50%\n","output_type":"stream"}]}]}